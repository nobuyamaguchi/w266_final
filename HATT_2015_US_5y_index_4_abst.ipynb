{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-storage\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep only quality_index_6 >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 30)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_quality = pd.read_csv('US_patent_abstract_5000_2015_with_title_1_5y.csv')\n",
    "df_merge_quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8642147026094559"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_merge_quality['quality_index_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0238514872446279"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_merge_quality['quality_index_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_merge_quality['quality_index_4'], density=False)  # `density=False` would make counts\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Quality_Index_4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>publication_number</th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>title_text</th>\n",
       "      <th>claims_text</th>\n",
       "      <th>publication_number_match</th>\n",
       "      <th>appln_id</th>\n",
       "      <th>pub_nbr</th>\n",
       "      <th>filing</th>\n",
       "      <th>...</th>\n",
       "      <th>fwd_cits7</th>\n",
       "      <th>breakthrough</th>\n",
       "      <th>generality</th>\n",
       "      <th>originality</th>\n",
       "      <th>radicalness</th>\n",
       "      <th>renewal</th>\n",
       "      <th>quality_index_4</th>\n",
       "      <th>quality_index_6</th>\n",
       "      <th>quality_rank</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>701919</td>\n",
       "      <td>US-9210117-B2</td>\n",
       "      <td>An invitation information push method includes...</td>\n",
       "      <td>20130208</td>\n",
       "      <td>Invitation information push method and system</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. An invi...</td>\n",
       "      <td>US09210117</td>\n",
       "      <td>407142987</td>\n",
       "      <td>US09210117</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520408</td>\n",
       "      <td>0.914825</td>\n",
       "      <td>0.402597</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.229088</td>\n",
       "      <td>0.251782</td>\n",
       "      <td>0</td>\n",
       "      <td>Invitation information push method and system....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356119</td>\n",
       "      <td>US-8715323-B2</td>\n",
       "      <td>A connector is provided for linear implants su...</td>\n",
       "      <td>20111017</td>\n",
       "      <td>Coronal angulating connector</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. An impl...</td>\n",
       "      <td>US08715323</td>\n",
       "      <td>405679017</td>\n",
       "      <td>US08715323</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.118815</td>\n",
       "      <td>0.198961</td>\n",
       "      <td>0</td>\n",
       "      <td>Coronal angulating connector. A connector is p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>832228</td>\n",
       "      <td>US-9414578-B2</td>\n",
       "      <td>A device for spearfishing, which device may in...</td>\n",
       "      <td>20131119</td>\n",
       "      <td>Spearfishing apparatus</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A spear...</td>\n",
       "      <td>US09414578</td>\n",
       "      <td>440484304</td>\n",
       "      <td>US09414578</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.739062</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.353373</td>\n",
       "      <td>0.411789</td>\n",
       "      <td>1</td>\n",
       "      <td>Spearfishing apparatus. A device for spearfish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170137</td>\n",
       "      <td>US-7987148-B2</td>\n",
       "      <td>Disclosed are embodiments of systems and metho...</td>\n",
       "      <td>20100520</td>\n",
       "      <td>Systems and methods for prioritizing media fil...</td>\n",
       "      <td>1. A computer-implemented method for the autom...</td>\n",
       "      <td>US07987148</td>\n",
       "      <td>328063700</td>\n",
       "      <td>US07987148</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713885</td>\n",
       "      <td>0.958138</td>\n",
       "      <td>0.566996</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.482869</td>\n",
       "      <td>0.629272</td>\n",
       "      <td>1</td>\n",
       "      <td>Systems and methods for prioritizing media fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156457</td>\n",
       "      <td>US-8519743-B2</td>\n",
       "      <td>A semiconductor integrated circuit comprises a...</td>\n",
       "      <td>20100312</td>\n",
       "      <td>Semiconductor integrated circuit</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A semic...</td>\n",
       "      <td>US08519743</td>\n",
       "      <td>331361461</td>\n",
       "      <td>US08519743</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.534979</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.250661</td>\n",
       "      <td>0.252287</td>\n",
       "      <td>0</td>\n",
       "      <td>Semiconductor integrated circuit. A semiconduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>374073</td>\n",
       "      <td>US-8713032-B2</td>\n",
       "      <td>Methods, systems and articles of manufacture f...</td>\n",
       "      <td>20111202</td>\n",
       "      <td>Cross-platform cloud-based map creation</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A compu...</td>\n",
       "      <td>US08713032</td>\n",
       "      <td>365873243</td>\n",
       "      <td>US08713032</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686914</td>\n",
       "      <td>0.931641</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.457711</td>\n",
       "      <td>0.428220</td>\n",
       "      <td>1</td>\n",
       "      <td>Cross-platform cloud-based map creation. Metho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>609358</td>\n",
       "      <td>US-8835927-B2</td>\n",
       "      <td>A display substrate includes a gate line exten...</td>\n",
       "      <td>20121114</td>\n",
       "      <td>Display substrate</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A displ...</td>\n",
       "      <td>US08835927</td>\n",
       "      <td>410675886</td>\n",
       "      <td>US08835927</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.359248</td>\n",
       "      <td>0.361225</td>\n",
       "      <td>1</td>\n",
       "      <td>Display substrate. A display substrate include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>618209</td>\n",
       "      <td>US-9181277-B2</td>\n",
       "      <td>The present invention relates to the field of ...</td>\n",
       "      <td>20121114</td>\n",
       "      <td>Aminoquinazoline derivatives and their salts a...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A compo...</td>\n",
       "      <td>US09181277</td>\n",
       "      <td>420889733</td>\n",
       "      <td>US09181277</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472659</td>\n",
       "      <td>0.911124</td>\n",
       "      <td>0.198413</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.325389</td>\n",
       "      <td>1</td>\n",
       "      <td>Aminoquinazoline derivatives and their salts a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>242142</td>\n",
       "      <td>US-9221342-B2</td>\n",
       "      <td>A method for displaying graphical objects. The...</td>\n",
       "      <td>20110331</td>\n",
       "      <td>Method and device for displaying information i...</td>\n",
       "      <td>The invention claimed is: \\n     \\n       1. A...</td>\n",
       "      <td>US09221342</td>\n",
       "      <td>381597066</td>\n",
       "      <td>US09221342</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.655223</td>\n",
       "      <td>0.934055</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.476494</td>\n",
       "      <td>0.403608</td>\n",
       "      <td>1</td>\n",
       "      <td>Method and device for displaying information i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>564583</td>\n",
       "      <td>US-8960017-B2</td>\n",
       "      <td>A method of retrofitting an orifice meter incl...</td>\n",
       "      <td>20121114</td>\n",
       "      <td>System and method for ultrasonic metering usin...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A flow ...</td>\n",
       "      <td>US08960017</td>\n",
       "      <td>417939986</td>\n",
       "      <td>US08960017</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795923</td>\n",
       "      <td>0.562454</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.471472</td>\n",
       "      <td>0.433156</td>\n",
       "      <td>1</td>\n",
       "      <td>System and method for ultrasonic metering usin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 publication_number  \\\n",
       "0         701919      US-9210117-B2   \n",
       "1         356119      US-8715323-B2   \n",
       "2         832228      US-9414578-B2   \n",
       "3         170137      US-7987148-B2   \n",
       "4         156457      US-8519743-B2   \n",
       "...          ...                ...   \n",
       "4995      374073      US-8713032-B2   \n",
       "4996      609358      US-8835927-B2   \n",
       "4997      618209      US-9181277-B2   \n",
       "4998      242142      US-9221342-B2   \n",
       "4999      564583      US-8960017-B2   \n",
       "\n",
       "                                          abstract_text  filing_date  \\\n",
       "0     An invitation information push method includes...     20130208   \n",
       "1     A connector is provided for linear implants su...     20111017   \n",
       "2     A device for spearfishing, which device may in...     20131119   \n",
       "3     Disclosed are embodiments of systems and metho...     20100520   \n",
       "4     A semiconductor integrated circuit comprises a...     20100312   \n",
       "...                                                 ...          ...   \n",
       "4995  Methods, systems and articles of manufacture f...     20111202   \n",
       "4996  A display substrate includes a gate line exten...     20121114   \n",
       "4997  The present invention relates to the field of ...     20121114   \n",
       "4998  A method for displaying graphical objects. The...     20110331   \n",
       "4999  A method of retrofitting an orifice meter incl...     20121114   \n",
       "\n",
       "                                             title_text  \\\n",
       "0         Invitation information push method and system   \n",
       "1                          Coronal angulating connector   \n",
       "2                                Spearfishing apparatus   \n",
       "3     Systems and methods for prioritizing media fil...   \n",
       "4                      Semiconductor integrated circuit   \n",
       "...                                                 ...   \n",
       "4995            Cross-platform cloud-based map creation   \n",
       "4996                                  Display substrate   \n",
       "4997  Aminoquinazoline derivatives and their salts a...   \n",
       "4998  Method and device for displaying information i...   \n",
       "4999  System and method for ultrasonic metering usin...   \n",
       "\n",
       "                                            claims_text  \\\n",
       "0     What is claimed is: \\n     \\n       1. An invi...   \n",
       "1     What is claimed is: \\n     \\n       1. An impl...   \n",
       "2     What is claimed is: \\n     \\n       1. A spear...   \n",
       "3     1. A computer-implemented method for the autom...   \n",
       "4     What is claimed is: \\n     \\n       1. A semic...   \n",
       "...                                                 ...   \n",
       "4995  What is claimed is: \\n     \\n       1. A compu...   \n",
       "4996  What is claimed is: \\n     \\n       1. A displ...   \n",
       "4997  What is claimed is: \\n     \\n       1. A compo...   \n",
       "4998  The invention claimed is: \\n     \\n       1. A...   \n",
       "4999  What is claimed is: \\n     \\n       1. A flow ...   \n",
       "\n",
       "     publication_number_match   appln_id     pub_nbr  filing  ...  fwd_cits7  \\\n",
       "0                  US09210117  407142987  US09210117    2013  ...          2   \n",
       "1                  US08715323  405679017  US08715323    2011  ...         15   \n",
       "2                  US09414578  440484304  US09414578    2013  ...          7   \n",
       "3                  US07987148  328063700  US07987148    2010  ...        122   \n",
       "4                  US08519743  331361461  US08519743    2010  ...          3   \n",
       "...                       ...        ...         ...     ...  ...        ...   \n",
       "4995               US08713032  365873243  US08713032    2011  ...          4   \n",
       "4996               US08835927  410675886  US08835927    2012  ...          6   \n",
       "4997               US09181277  420889733  US09181277    2012  ...         26   \n",
       "4998               US09221342  381597066  US09221342    2011  ...          4   \n",
       "4999               US08960017  417939986  US08960017    2012  ...          8   \n",
       "\n",
       "      breakthrough  generality  originality  radicalness  renewal  \\\n",
       "0                0    0.520408     0.914825     0.402597      2.0   \n",
       "1                0    0.000000     0.226843     0.130435      3.0   \n",
       "2                0    0.753968     0.739062     0.087500      3.0   \n",
       "3                0    0.713885     0.958138     0.566996      5.0   \n",
       "4                0    0.320000     0.534979     0.296296      7.0   \n",
       "...            ...         ...          ...          ...      ...   \n",
       "4995             0    0.686914     0.931641     0.656250      3.0   \n",
       "4996             0    0.659722     0.666667     1.000000      2.0   \n",
       "4997             0    0.472659     0.911124     0.198413      3.0   \n",
       "4998             0    0.655223     0.934055     0.850340      4.0   \n",
       "4999             0    0.795923     0.562454     0.297297      3.0   \n",
       "\n",
       "      quality_index_4  quality_index_6  quality_rank  \\\n",
       "0            0.229088         0.251782             0   \n",
       "1            0.118815         0.198961             0   \n",
       "2            0.353373         0.411789             1   \n",
       "3            0.482869         0.629272             1   \n",
       "4            0.250661         0.252287             0   \n",
       "...               ...              ...           ...   \n",
       "4995         0.457711         0.428220             1   \n",
       "4996         0.359248         0.361225             1   \n",
       "4997         0.300691         0.325389             1   \n",
       "4998         0.476494         0.403608             1   \n",
       "4999         0.471472         0.433156             1   \n",
       "\n",
       "                                                   text  \n",
       "0     Invitation information push method and system....  \n",
       "1     Coronal angulating connector. A connector is p...  \n",
       "2     Spearfishing apparatus. A device for spearfish...  \n",
       "3     Systems and methods for prioritizing media fil...  \n",
       "4     Semiconductor integrated circuit. A semiconduc...  \n",
       "...                                                 ...  \n",
       "4995  Cross-platform cloud-based map creation. Metho...  \n",
       "4996  Display substrate. A display substrate include...  \n",
       "4997  Aminoquinazoline derivatives and their salts a...  \n",
       "4998  Method and device for displaying information i...  \n",
       "4999  System and method for ultrasonic metering usin...  \n",
       "\n",
       "[5000 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle as cPickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH = 30\n",
    "MAX_SENTS = 30\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_merge_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 30)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2992\n",
       "1    2008\n",
       "Name: quality_rank, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['quality_rank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5984"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2992/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/nobu_yamaguchi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "claims = []\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for idx in range(data_train.text.shape[0]):\n",
    "\n",
    "    text = clean_str(str(data_train.iloc[idx]['text']))\n",
    "    texts.append(text)\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    claims.append(sentences)\n",
    "    labels.append(data_train.iloc[idx]['quality_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "data = np.zeros((len(texts), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 30, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentences in enumerate(claims):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k = 0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "            #for word in wordTokens:\n",
    "                if word in tokenizer.word_index.keys():\n",
    "                    if (k < MAX_SENT_LENGTH) and (tokenizer.word_index[word] < MAX_NB_WORDS):\n",
    "                        data[i, j, k] = tokenizer.word_index[word]\n",
    "                        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3894,   45, 2436,   15,    4,   24,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   8, 3894,   45, 2436,   15,   22,  340,  101,    8, 3894,  273,\n",
       "        1151,   21,    2, 6132,   59,    2,  235, 1207, 3894,   45,    5,\n",
       "           2,  230,    3, 3053,  147,    5, 7857,  742],\n",
       "       [   1,   15,  122,   92,   64,    2,  219,  100,    6, 3344,    2,\n",
       "         235, 5142, 1207, 3894,   45,    5,   16,   28,   19,  487,  147,\n",
       "           5,   16,   28,   19,   59, 2358,   49,  154],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16864 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (5000, 30, 30)\n",
      "Shape of label tensor: (5000, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3894,   45, 2436,   15,    4,   24,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   8, 3894,   45, 2436,   15,   22,  340,  101,    8, 3894,  273,\n",
       "        1151,   21,    2, 6132,   59,    2,  235, 1207, 3894,   45,    5,\n",
       "           2,  230,    3, 3053,  147,    5, 7857,  742],\n",
       "       [   1,   15,  122,   92,   64,    2,  219,  100,    6, 3344,    2,\n",
       "         235, 5142, 1207, 3894,   45,    5,   16,   28,   19,  487,  147,\n",
       "           5,   16,   28,   19,   59, 2358,   49,  154],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = np.arange(data.shape[0])\n",
    "#np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[indices]\n",
    "#labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive and negative reviews in traing and validation set\n",
      "[2397. 1603.]\n",
      "[595. 405.]\n"
     ]
    }
   ],
   "source": [
    "print('Number of positive and negative reviews in traing and validation set')\n",
    "print(y_train.sum(axis=0))\n",
    "print(y_val.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python helper libraries.\n",
    "import os, sys, re, json, time\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display\n",
    "\n",
    "# NumPy and SciPy for matrix ops\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "#from w266_common import utils, vocabulary, tf_embed_viz\n",
    "#import glove_helper; reload(glove_helper)\n",
    "\n",
    "#hands = glove_helper.Hands(ndim=100)  # 50, 100, 200, 300 dim are available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"data/glove/glove.6B.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data/glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"data/glove\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building Hierachical Attention network\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SENT_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttLayer(Layer):\n",
    "    def __init__(self, attention_dim):\n",
    "        self.init = initializers.get('normal')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)), name='W')\n",
    "        self.b = K.variable(self.init((self.attention_dim, )), name='b')\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)), name='u')\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "        super(AttLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # size of x :[batch_size, sel_len, attention_dim]\n",
    "        # size of u :[batch_size, attention_dim]\n",
    "        # uit = tanh(xW+b)\n",
    " \n",
    "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b)) #\n",
    "\n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "\n",
    "        ait = K.exp(ait)\n",
    "\n",
    "\n",
    "        #if mask is not None:\n",
    "        #    # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "        #    print('mask')\n",
    "        #    ait *= K.cast(mask, K.floatx())\n",
    "\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        ait = K.expand_dims(ait)\n",
    " \n",
    "        weighted_input = x * ait\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'att_layer_1/W:0' shape=(200, 100) dtype=float32> W\n",
      "tracking <tf.Variable 'att_layer_1/b:0' shape=(100,) dtype=float32> b\n",
      "tracking <tf.Variable 'att_layer_1/u:0' shape=(100, 1) dtype=float32> u\n"
     ]
    }
   ],
   "source": [
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sentence_input)\n",
    "l_lstm = Bidirectional(GRU(100, return_sequences=True))(embedded_sequences)\n",
    "l_att = AttLayer(100)(l_lstm)\n",
    "sentEncoder = Model(sentence_input, l_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "claims_encoder = TimeDistributed(sentEncoder)(claims_input)\n",
    "l_lstm_sent = Bidirectional(GRU(30, return_sequences=True))(claims_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 30, 60])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_lstm_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'att_layer_2/W:0' shape=(60, 100) dtype=float32> W\n",
      "tracking <tf.Variable 'att_layer_2/b:0' shape=(100,) dtype=float32> b\n",
      "tracking <tf.Variable 'att_layer_2/u:0' shape=(100, 1) dtype=float32> u\n"
     ]
    }
   ],
   "source": [
    "#l_att_sent = AttLayer(100)(l_lstm_sent)\n",
    "l_att_sent = AttLayer(100)(l_lstm_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_att_dense = Dense(100, activation='relu')(l_att_sent)\n",
    "l_att_dense = Dense(100, activation='relu')(l_att_dense)\n",
    "l_att_dense = Dense(100, activation='relu')(l_att_dense)\n",
    "l_att_sent_drop = Dropout(rate=0.2)(l_att_dense)\n",
    "preds = Dense(2, activation='sigmoid')(l_att_sent_drop)\n",
    "model = Model(claims_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network 0.2\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "4000/4000 [==============================] - 101s 25ms/step - loss: 0.6778 - acc: 0.5938 - val_loss: 0.6752 - val_acc: 0.5950\n",
      "Epoch 2/5\n",
      "4000/4000 [==============================] - 94s 23ms/step - loss: 0.6700 - acc: 0.5995 - val_loss: 0.6684 - val_acc: 0.5960\n",
      "Epoch 3/5\n",
      "4000/4000 [==============================] - 90s 22ms/step - loss: 0.6692 - acc: 0.6040 - val_loss: 0.6704 - val_acc: 0.5925\n",
      "Epoch 4/5\n",
      "4000/4000 [==============================] - 49s 12ms/step - loss: 0.6565 - acc: 0.6187 - val_loss: 0.6784 - val_acc: 0.5595\n",
      "Epoch 5/5\n",
      "4000/4000 [==============================] - 49s 12ms/step - loss: 0.6495 - acc: 0.6269 - val_loss: 0.6648 - val_acc: 0.6030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc734487c90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network 0.2\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=5, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(x_val)\n",
    "np.savetxt('HATT_abst.csv', pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/HATT_5y_abst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
