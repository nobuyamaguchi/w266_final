{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "# reference https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for data\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "## for bert language model\n",
    "import transformers\n",
    "\n",
    "# for checkpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "# string processing\n",
    "import re\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing, feature_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to navigate to the data location\n",
    "import os\n",
    "\n",
    "# get current directory \n",
    "path = os.getcwd() \n",
    "\n",
    "# parent directory\n",
    "parent = os.path.dirname(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_quality = pd.read_csv(parent + '/data/US_patent_abstract_5000_2015_with_title_1_5y.csv')\n",
    "df_merge_quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claims_text</th>\n",
       "      <th>quality_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is claimed is: \\n     \\n       1. An invi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is claimed is: \\n     \\n       1. An impl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is claimed is: \\n     \\n       1. A spear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. A computer-implemented method for the autom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is claimed is: \\n     \\n       1. A semic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>What is claimed is: \\n     \\n       1. A compu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>What is claimed is: \\n     \\n       1. A displ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>What is claimed is: \\n     \\n       1. A compo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>The invention claimed is: \\n     \\n       1. A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>What is claimed is: \\n     \\n       1. A flow ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            claims_text  quality_rank\n",
       "0     What is claimed is: \\n     \\n       1. An invi...             0\n",
       "1     What is claimed is: \\n     \\n       1. An impl...             0\n",
       "2     What is claimed is: \\n     \\n       1. A spear...             1\n",
       "3     1. A computer-implemented method for the autom...             1\n",
       "4     What is claimed is: \\n     \\n       1. A semic...             0\n",
       "...                                                 ...           ...\n",
       "4995  What is claimed is: \\n     \\n       1. A compu...             1\n",
       "4996  What is claimed is: \\n     \\n       1. A displ...             1\n",
       "4997  What is claimed is: \\n     \\n       1. A compo...             1\n",
       "4998  The invention claimed is: \\n     \\n       1. A...             1\n",
       "4999  What is claimed is: \\n     \\n       1. A flow ...             1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_merge_quality[['claims_text', 'quality_rank']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## distil-bert tokenizer\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    sentence = re.sub(r\"\\\\\", \"\", sentence)    \n",
    "    sentence = re.sub(r\"\\'\", \"\", sentence)    \n",
    "    sentence = re.sub(r\"\\\"\", \"\", sentence)    \n",
    "    \n",
    "\n",
    "    return sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = []\n",
    "sentences = list(df['claims_text'])\n",
    "for sen in sentences:\n",
    "    claims.append(preprocess_text(str(sen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is claimed is An invitation information push method comprising after receiving an invitation request sent by microblog user server sending invitation information to clients corresponding to number of invited users carried in the invitation request wherein the invited users are users who have not registered microblog and the number of the invited users is greater than or equal to and upon receiving the invitation information each client creating an invitation information guide to guide the user who has not registered microblog to register microblog wherein the server sending the invitation information to the clients corresponding to the invited users comprises determining by the server whether one or more of the invited users carried in the invitation request are in restricted list and if none of the invited users carried in the invitation request is in the restricted list sending the invitation information to the clients corresponding to the invited users carried in the invitation request if microblogging operation is not in high risk period wherein the sending the invitation information to the clients corresponding to the invited users comprises determining level of an invitation qualification corresponding to the microblog user who sends the invitation request and according to preset corresponding relation between the level of the invitation qualification and the number of invited users determining whether the number of the invited users carried in the invitation request is less than or equal to the number of invited users corresponding to the determined level of the invitation qualification if yes sending the invitation information to the clients corresponding to the invited users carried in the invitation request The method according to claim wherein the clients corresponding to the users who have not registered microblog comprise clients of the users who have not registered microblog in one network segment or clients corresponding to friends of designated microblog user the friends have not registered microblog and are obtained through instant communication relation chains of the designated microblog user or clients of randomly selected users who have not registered microblog The method according to claim wherein the invitation request sent by the microblog user is sent to the server through following steps when the server receives an invitation triggered by the microblog user the server judges whether the microblog user has an invitation qualification if yes the server provides microblog invitation interface to client of the microblog user and the server receives the invitation request sent by the client of the microblog user wherein the invited users carried in the invitation request are selected by the microblog user from list of users who have not registered microblog the list of users is provided in the microblog invitation interface The method according to claim wherein the clients at least comprises at least one of wireless terminal PC client and web side The method according to claim wherein the invitation information contains at least one of hot user hot information and persons whom the invited users who receive the invitation information may know and creating an invitation information guide further comprises displaying content contained in the invitation information on the invitation information guide for users who receive the invitation information to view The method according to claim wherein the method further comprises when predetermined time is reached the server actively sending the invitation information to the clients corresponding to the user who have not registered microblog An invitation information push system comprising server comprising processor for executing modules stored in non transitory computer readable storage medium to execute the following procedure after receiving an invitation request sent by microblog user send invitation information to clients corresponding to number of invited users carried in the invitation request wherein the invited users are users who have not registered microblog and the number of the invited users is greater than or equal to and upon receiving the invitation information create an invitation information guide to guide the users who have not registered microblog to register microblog wherein the modules of the server comprise determining module configured to after receiving the invitation request determine whether one or more of the invited users carried in the invitation request are in restricted list sending module configured to when determination result of the determining module is no send the invitation information to the clients corresponding to the invited users carried in the invitation request if the microblogging operation is not in high risk period wherein the sending module comprises determining unit configured to determine level of an invitation qualification corresponding to the microblog user who sends the invitation request and sending unit configured to according to preset corresponding relation between the level of the invitation qualification and the number of invited users determine whether the number of the invited users carried in the invitation request is less than or equal to number of invited users corresponding to the determined level of the invitation qualification if yes send the invitation information to the clients corresponding to the invited users carried in the invitation request The system according to claim wherein the modules of the server are further to execute the following procedure when set time is reached actively send invitation information to the clients corresponding to the invited users who have not registered microblog The system according to claim wherein the clients corresponding to the users who have not registered microblog comprise clients of the users who have not registered microblog in one network segment or clients corresponding to friends of designated microblog user the friends have not registered microblog and are obtained through instant communication relation chains of the designated microblog user or clients of randomly selected users who have not registered microblog An invitation information push method comprising sending by server when predetermined time is reached invitation information to at least one client corresponding to at least one user who has not registered microblog receiving the invitation information by the at least one client corresponding to the at least one user who has not registered microblog and creating by each of the at least one client an invitation information guide to guide the at least one user who has not registered microblog to register microblog wherein the server sending the invitation information to at least one client corresponding to at least one user who has not registered microblog comprises sending by microblog user an invitation request to the server determining by the server whether one or more of invited users carried in the invitation request are in restricted list and if none of the invited users carried in the invitation request is in the restricted list sending the invitation information to clients corresponding to the invited users carried in the invitation request wherein the sending invitation information to at east one client corresponding to at least one user who has not registered microblog comprises sending by microblog user an invitation request to the server determining level of an invitation qualification corresponding to the microblog user who sends the invitation request and according to preset corresponding relation between the level of the invitation qualification and the number of invited users determining whether the number of the invited users carried in the invitation request is less than or equal to the number of invited users corresponding to the determined level of the invitation qualification if yes sending the invitation information to clients corresponding to the invited users carried in the invitation request The method according to claim wherein the at least one client corresponding to at least one user who has not registered microblog comprises client of the at least one user who has not registered microblog in one network segment or clients corresponding to friends of designated microblog user the friends have not registered microblog and are obtained through instant communication relation chains of the designated microblog user or clients of randomly selected users who have not registered microblog'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize data for BERT input\n",
    "def encode_sentence(sent, max_seq_length):\n",
    "    tok_sent = tokenizer.tokenize(sent)\n",
    "    length = len(tok_sent)\n",
    "    if length <= max_seq_length:\n",
    "        return [\"[CLS] \"] + tok_sent+ [\" [SEP] \"] + [\" [PAD] \"] * (max_seq_length - length) # make sure is [\"SEP\"] the list * number. Otherwise it doesn't add up to your desired number!\n",
    "    else: # BERT limited to 512 tokens\n",
    "        return [\"[CLS] \"] + tok_sent[:max_seq_length] + [\" [SEP] \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the input data to feed into BERT\n",
    "corpus_train = claims[:4000]\n",
    "maxlen = 510\n",
    "\n",
    "## add special tokens\n",
    "# the initial code will have consistency issue if some text are longer than maxlen, and some shorten, and cause error in X_train at the bottom (so I count its unique value => (array([500, 501, 502, 503]), array([ 805,    5,    3, 4187])))\n",
    "# So I adjust the code to remove the .split(\" \") and prcesss use list instead !\n",
    "# and the process gets more efficient as well!\n",
    "\n",
    "corpus_tokenized = [encode_sentence(txt, maxlen) for txt in corpus_train]\n",
    "\n",
    "## generate masks\n",
    "masks = [[1]*len(txt) + [0]*(maxlen - len(\n",
    "           txt)) for txt in corpus_tokenized]\n",
    "    \n",
    "## padding\n",
    "txt2seq = [txt + [\" [PAD]\"]*(maxlen-len(txt)) if len(txt) != maxlen else txt for txt in corpus_tokenized]\n",
    "    \n",
    "## generate idx\n",
    "idx = [tokenizer.convert_tokens_to_ids (seq) for seq in txt2seq]  # I think the problem is here, the tokenizer.encode() seems automatically adding a [CLS] up-front..\n",
    "#idx = [tokenizer.encode(seq.split(\" \")) for seq in txt2seq]    \n",
    "\n",
    "## generate segments\n",
    "segments = [] \n",
    "for seq in txt2seq:\n",
    "    temp, i = [], 0\n",
    "    for token in seq:\n",
    "        temp.append(i)\n",
    "        if token == \"[SEP]\":\n",
    "             i += 1\n",
    "    segments.append(temp)\n",
    "## feature matrix\n",
    "X_train = [np.asarray(idx, dtype='int32'), \n",
    "           np.asarray(masks, dtype='int32'), \n",
    "           np.asarray(segments, dtype='int32')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  101,  2054,  2003, ...,  1998,  4773,   102],\n",
       "        [  101,  2054,  2003, ...,  2029,  2003,   102],\n",
       "        [  101,  2054,  2003, ...,  1996, 12341,   102],\n",
       "        ...,\n",
       "        [  101,  2054,  2003, ...,  2445,  2005,   102],\n",
       "        [  101,  2057,  4366, ..., 14021, 21332,   102],\n",
       "        [  101,  1996, 11028, ...,  2011,  2029,   102]], dtype=int32),\n",
       " array([[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]], dtype=int32),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4000, 512)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt:  What is claimed is An invitation information push method comprising after receiving an invitation request sent by microblog user server sending invitation information to clients corresponding to number of invited users carried in the invitation request wherein the invited users are users who have not registered microblog and the number of the invited users is greater than or equal to and upon receiving the invitation information each client creating an invitation information guide to guide the user who has not registered microblog to register microblog wherein the server sending the invitation information to the clients corresponding to the invited users comprises determining by the server whether one or more of the invited users carried in the invitation request are in restricted list and if none of the invited users carried in the invitation request is in the restricted list sending the invitation information to the clients corresponding to the invited users carried in the invitation request if microblogging operation is not in high risk period wherein the sending the invitation information to the clients corresponding to the invited users comprises determining level of an invitation qualification corresponding to the microblog user who sends the invitation request and according to preset corresponding relation between the level of the invitation qualification and the number of invited users determining whether the number of the invited users carried in the invitation request is less than or equal to the number of invited users corresponding to the determined level of the invitation qualification if yes sending the invitation information to the clients corresponding to the invited users carried in the invitation request The method according to claim wherein the clients corresponding to the users who have not registered microblog comprise clients of the users who have not registered microblog in one network segment or clients corresponding to friends of designated microblog user the friends have not registered microblog and are obtained through instant communication relation chains of the designated microblog user or clients of randomly selected users who have not registered microblog The method according to claim wherein the invitation request sent by the microblog user is sent to the server through following steps when the server receives an invitation triggered by the microblog user the server judges whether the microblog user has an invitation qualification if yes the server provides microblog invitation interface to client of the microblog user and the server receives the invitation request sent by the client of the microblog user wherein the invited users carried in the invitation request are selected by the microblog user from list of users who have not registered microblog the list of users is provided in the microblog invitation interface The method according to claim wherein the clients at least comprises at least one of wireless terminal PC client and web side The method according to claim wherein the invitation information contains at least one of hot user hot information and persons whom the invited users who receive the invitation information may know and creating an invitation information guide further comprises displaying content contained in the invitation information on the invitation information guide for users who receive the invitation information to view The method according to claim wherein the method further comprises when predetermined time is reached the server actively sending the invitation information to the clients corresponding to the user who have not registered microblog An invitation information push system comprising server comprising processor for executing modules stored in non transitory computer readable storage medium to execute the following procedure after receiving an invitation request sent by microblog user send invitation information to clients corresponding to number of invited users carried in the invitation request wherein the invited users are users who have not registered microblog and the number of the invited users is greater than or equal to and upon receiving the invitation information create an invitation information guide to guide the users who have not registered microblog to register microblog wherein the modules of the server comprise determining module configured to after receiving the invitation request determine whether one or more of the invited users carried in the invitation request are in restricted list sending module configured to when determination result of the determining module is no send the invitation information to the clients corresponding to the invited users carried in the invitation request if the microblogging operation is not in high risk period wherein the sending module comprises determining unit configured to determine level of an invitation qualification corresponding to the microblog user who sends the invitation request and sending unit configured to according to preset corresponding relation between the level of the invitation qualification and the number of invited users determine whether the number of the invited users carried in the invitation request is less than or equal to number of invited users corresponding to the determined level of the invitation qualification if yes send the invitation information to the clients corresponding to the invited users carried in the invitation request The system according to claim wherein the modules of the server are further to execute the following procedure when set time is reached actively send invitation information to the clients corresponding to the invited users who have not registered microblog The system according to claim wherein the clients corresponding to the users who have not registered microblog comprise clients of the users who have not registered microblog in one network segment or clients corresponding to friends of designated microblog user the friends have not registered microblog and are obtained through instant communication relation chains of the designated microblog user or clients of randomly selected users who have not registered microblog An invitation information push method comprising sending by server when predetermined time is reached invitation information to at least one client corresponding to at least one user who has not registered microblog receiving the invitation information by the at least one client corresponding to the at least one user who has not registered microblog and creating by each of the at least one client an invitation information guide to guide the at least one user who has not registered microblog to register microblog wherein the server sending the invitation information to at least one client corresponding to at least one user who has not registered microblog comprises sending by microblog user an invitation request to the server determining by the server whether one or more of invited users carried in the invitation request are in restricted list and if none of the invited users carried in the invitation request is in the restricted list sending the invitation information to clients corresponding to the invited users carried in the invitation request wherein the sending invitation information to at east one client corresponding to at least one user who has not registered microblog comprises sending by microblog user an invitation request to the server determining level of an invitation qualification corresponding to the microblog user who sends the invitation request and according to preset corresponding relation between the level of the invitation qualification and the number of invited users determining whether the number of the invited users carried in the invitation request is less than or equal to the number of invited users corresponding to the determined level of the invitation qualification if yes sending the invitation information to clients corresponding to the invited users carried in the invitation request The method according to claim wherein the at least one client corresponding to at least one user who has not registered microblog comprises client of the at least one user who has not registered microblog in one network segment or clients corresponding to friends of designated microblog user the friends have not registered microblog and are obtained through instant communication relation chains of the designated microblog user or clients of randomly selected users who have not registered microblog\n",
      "tokenized: ['[CLS]', 'what', 'is', 'claimed', 'is', 'an', 'invitation', 'information', 'push', 'method', 'comprising', 'after', 'receiving', 'an', 'invitation', 'request', 'sent', 'by', 'micro', '##bl', '##og', 'user', 'server', 'sending', 'invitation', 'information', 'to', 'clients', 'corresponding', 'to', 'number', 'of', 'invited', 'users', 'carried', 'in', 'the', 'invitation', 'request', 'wherein', 'the', 'invited', 'users', 'are', 'users', 'who', 'have', 'not', 'registered', 'micro', '##bl', '##og', 'and', 'the', 'number', 'of', 'the', 'invited', 'users', 'is', 'greater', 'than', 'or', 'equal', 'to', 'and', 'upon', 'receiving', 'the', 'invitation', 'information', 'each', 'client', 'creating', 'an', 'invitation', 'information', 'guide', 'to', 'guide', 'the', 'user', 'who', 'has', 'not', 'registered', 'micro', '##bl', '##og', 'to', 'register', 'micro', '##bl', '##og', 'wherein', 'the', 'server', 'sending', 'the', 'invitation', 'information', 'to', 'the', 'clients', 'corresponding', 'to', 'the', 'invited', 'users', 'comprises', 'determining', 'by', 'the', 'server', 'whether', 'one', 'or', 'more', 'of', 'the', 'invited', 'users', 'carried', 'in', 'the', 'invitation', 'request', 'are', 'in', 'restricted', 'list', 'and', 'if', 'none', 'of', 'the', 'invited', 'users', 'carried', 'in', 'the', 'invitation', 'request', 'is', 'in', 'the', 'restricted', 'list', 'sending', 'the', 'invitation', 'information', 'to', 'the', 'clients', 'corresponding', 'to', 'the', 'invited', 'users', 'carried', 'in', 'the', 'invitation', 'request', 'if', 'micro', '##bl', '##og', '##ging', 'operation', 'is', 'not', 'in', 'high', 'risk', 'period', 'wherein', 'the', 'sending', 'the', 'invitation', 'information', 'to', 'the', 'clients', 'corresponding', 'to', 'the', 'invited', 'users', 'comprises', 'determining', 'level', 'of', 'an', 'invitation', 'qualification', 'corresponding', 'to', 'the', 'micro', '##bl', '##og', 'user', 'who', 'sends', 'the', 'invitation', 'request', 'and', 'according', 'to', 'pre', '##set', 'corresponding', 'relation', 'between', 'the', 'level', 'of', 'the', 'invitation', 'qualification', 'and', 'the', 'number', 'of', 'invited', 'users', 'determining', 'whether', 'the', 'number', 'of', 'the', 'invited', 'users', 'carried', 'in', 'the', 'invitation', 'request', 'is', 'less', 'than', 'or', 'equal', 'to', 'the', 'number', 'of', 'invited', 'users', 'corresponding', 'to', 'the', 'determined', 'level', 'of', 'the', 'invitation', 'qualification', 'if', 'yes', 'sending', 'the', 'invitation', 'information', 'to', 'the', 'clients', 'corresponding', 'to', 'the', 'invited', 'users', 'carried', 'in', 'the', 'invitation', 'request', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'clients', 'corresponding', 'to', 'the', 'users', 'who', 'have', 'not', 'registered', 'micro', '##bl', '##og', 'comprise', 'clients', 'of', 'the', 'users', 'who', 'have', 'not', 'registered', 'micro', '##bl', '##og', 'in', 'one', 'network', 'segment', 'or', 'clients', 'corresponding', 'to', 'friends', 'of', 'designated', 'micro', '##bl', '##og', 'user', 'the', 'friends', 'have', 'not', 'registered', 'micro', '##bl', '##og', 'and', 'are', 'obtained', 'through', 'instant', 'communication', 'relation', 'chains', 'of', 'the', 'designated', 'micro', '##bl', '##og', 'user', 'or', 'clients', 'of', 'randomly', 'selected', 'users', 'who', 'have', 'not', 'registered', 'micro', '##bl', '##og', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'invitation', 'request', 'sent', 'by', 'the', 'micro', '##bl', '##og', 'user', 'is', 'sent', 'to', 'the', 'server', 'through', 'following', 'steps', 'when', 'the', 'server', 'receives', 'an', 'invitation', 'triggered', 'by', 'the', 'micro', '##bl', '##og', 'user', 'the', 'server', 'judges', 'whether', 'the', 'micro', '##bl', '##og', 'user', 'has', 'an', 'invitation', 'qualification', 'if', 'yes', 'the', 'server', 'provides', 'micro', '##bl', '##og', 'invitation', 'interface', 'to', 'client', 'of', 'the', 'micro', '##bl', '##og', 'user', 'and', 'the', 'server', 'receives', 'the', 'invitation', 'request', 'sent', 'by', 'the', 'client', 'of', 'the', 'micro', '##bl', '##og', 'user', 'wherein', 'the', 'invited', 'users', 'carried', 'in', 'the', 'invitation', 'request', 'are', 'selected', 'by', 'the', 'micro', '##bl', '##og', 'user', 'from', 'list', 'of', 'users', 'who', 'have', 'not', 'registered', 'micro', '##bl', '##og', 'the', 'list', 'of', 'users', 'is', 'provided', 'in', 'the', 'micro', '##bl', '##og', 'invitation', 'interface', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'clients', 'at', 'least', 'comprises', 'at', 'least', 'one', 'of', 'wireless', 'terminal', 'pc', 'client', 'and', 'web', '[SEP]']\n",
      "idx:  [  101  2054  2003  3555  2003  2019  8468  2592  5245  4118  9605  2044\n",
      "  4909  2019  8468  5227  2741  2011 12702 16558  8649  5310  8241  6016\n",
      "  8468  2592  2000  7846  7978  2000  2193  1997  4778  5198  3344  1999\n",
      "  1996  8468  5227 16726  1996  4778  5198  2024  5198  2040  2031  2025\n",
      "  5068 12702 16558  8649  1998  1996  2193  1997  1996  4778  5198  2003\n",
      "  3618  2084  2030  5020  2000  1998  2588  4909  1996  8468  2592  2169\n",
      "  7396  4526  2019  8468  2592  5009  2000  5009  1996  5310  2040  2038\n",
      "  2025  5068 12702 16558  8649  2000  4236 12702 16558  8649 16726  1996\n",
      "  8241  6016  1996  8468  2592  2000  1996  7846  7978  2000  1996  4778\n",
      "  5198  8681 12515  2011  1996  8241  3251  2028  2030  2062  1997  1996\n",
      "  4778  5198  3344  1999  1996  8468  5227  2024  1999  7775  2862  1998\n",
      "  2065  3904  1997  1996  4778  5198  3344  1999  1996  8468  5227  2003\n",
      "  1999  1996  7775  2862  6016  1996  8468  2592  2000  1996  7846  7978\n",
      "  2000  1996  4778  5198  3344  1999  1996  8468  5227  2065 12702 16558\n",
      "  8649  4726  3169  2003  2025  1999  2152  3891  2558 16726  1996  6016\n",
      "  1996  8468  2592  2000  1996  7846  7978  2000  1996  4778  5198  8681\n",
      " 12515  2504  1997  2019  8468  8263  7978  2000  1996 12702 16558  8649\n",
      "  5310  2040 10255  1996  8468  5227  1998  2429  2000  3653 13462  7978\n",
      "  7189  2090  1996  2504  1997  1996  8468  8263  1998  1996  2193  1997\n",
      "  4778  5198 12515  3251  1996  2193  1997  1996  4778  5198  3344  1999\n",
      "  1996  8468  5227  2003  2625  2084  2030  5020  2000  1996  2193  1997\n",
      "  4778  5198  7978  2000  1996  4340  2504  1997  1996  8468  8263  2065\n",
      "  2748  6016  1996  8468  2592  2000  1996  7846  7978  2000  1996  4778\n",
      "  5198  3344  1999  1996  8468  5227  1996  4118  2429  2000  4366 16726\n",
      "  1996  7846  7978  2000  1996  5198  2040  2031  2025  5068 12702 16558\n",
      "  8649 15821  7846  1997  1996  5198  2040  2031  2025  5068 12702 16558\n",
      "  8649  1999  2028  2897  6903  2030  7846  7978  2000  2814  1997  4351\n",
      " 12702 16558  8649  5310  1996  2814  2031  2025  5068 12702 16558  8649\n",
      "  1998  2024  4663  2083  7107  4807  7189  8859  1997  1996  4351 12702\n",
      " 16558  8649  5310  2030  7846  1997 18154  3479  5198  2040  2031  2025\n",
      "  5068 12702 16558  8649  1996  4118  2429  2000  4366 16726  1996  8468\n",
      "  5227  2741  2011  1996 12702 16558  8649  5310  2003  2741  2000  1996\n",
      "  8241  2083  2206  4084  2043  1996  8241  8267  2019  8468 13330  2011\n",
      "  1996 12702 16558  8649  5310  1996  8241  6794  3251  1996 12702 16558\n",
      "  8649  5310  2038  2019  8468  8263  2065  2748  1996  8241  3640 12702\n",
      " 16558  8649  8468  8278  2000  7396  1997  1996 12702 16558  8649  5310\n",
      "  1998  1996  8241  8267  1996  8468  5227  2741  2011  1996  7396  1997\n",
      "  1996 12702 16558  8649  5310 16726  1996  4778  5198  3344  1999  1996\n",
      "  8468  5227  2024  3479  2011  1996 12702 16558  8649  5310  2013  2862\n",
      "  1997  5198  2040  2031  2025  5068 12702 16558  8649  1996  2862  1997\n",
      "  5198  2003  3024  1999  1996 12702 16558  8649  8468  8278  1996  4118\n",
      "  2429  2000  4366 16726  1996  7846  2012  2560  8681  2012  2560  2028\n",
      "  1997  9949  5536  7473  7396  1998  4773   102]\n",
      "mask:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "segment:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(\"txt: \", claims[0])\n",
    "print(\"tokenized:\", [tokenizer.convert_ids_to_tokens(idx) for idx in X_train[0][i].tolist()])\n",
    "print(\"idx: \", X_train[0][i])\n",
    "print(\"mask: \", X_train[1][i])\n",
    "print(\"segment: \", X_train[2][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_idx (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_6 (TFDisti ((None, 512, 768),)  66362880    input_idx[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 768)          0           tf_distil_bert_model_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           49216       global_average_pooling1d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 2)            130         dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 66,412,226\n",
      "Trainable params: 49,346\n",
      "Non-trainable params: 66,362,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## inputs\n",
    "idx = layers.Input((maxlen+2), dtype=\"int32\", name=\"input_idx\")\n",
    "masks = layers.Input((maxlen+2), dtype=\"int32\", name=\"input_masks\")\n",
    "## pre-trained bert with config\n",
    "config = transformers.DistilBertConfig(dropout=0.2, \n",
    "           attention_dropout=0.2)\n",
    "config.output_hidden_states = False\n",
    "nlp = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n",
    "bert_out = nlp(idx, attention_mask=masks)[0]\n",
    "## fine-tuning\n",
    "x = layers.GlobalAveragePooling1D()(bert_out)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "y_out = layers.Dense(2, activation='sigmoid')(x)\n",
    "## compile\n",
    "model = models.Model([idx, masks], y_out)\n",
    "for layer in model.layers[:3]:\n",
    "    layer.trainable = False\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the test input data to feed into BERT\n",
    "corpus_train = claims[4000:]\n",
    "maxlen = 510\n",
    "\n",
    "## add special tokens\n",
    "# the initial code will have consistency issue if some text are longer than maxlen, and some shorten, and cause error in X_train at the bottom (so I count its unique value => (array([500, 501, 502, 503]), array([ 805,    5,    3, 4187])))\n",
    "# So I adjust the code to remove the .split(\" \") and prcesss use list instead !\n",
    "# and the process gets more efficient as well!\n",
    "'''\n",
    "maxqnans = np.int((maxlen-20)/2)\n",
    "corpus_tokenized = [\"[CLS] \"+\n",
    "             \" \".join(tokenizer.tokenize(re.sub(r'[^\\w\\s]+|\\n', '', \n",
    "             str(txt).lower().strip()))[:maxlen])+\n",
    "             \" [SEP] \" for txt in corpus]  # truncate each claim to the limit maxqnans length\n",
    "'''\n",
    "\n",
    "corpus_tokenized = [encode_sentence(txt, maxlen) for txt in corpus_train]\n",
    "\n",
    "## generate masks\n",
    "masks = [[1]*len(txt) + [0]*(maxlen - len(\n",
    "           txt)) for txt in corpus_tokenized]\n",
    "    \n",
    "## padding\n",
    "txt2seq = [txt + [\" [PAD]\"]*(maxlen-len(txt)) if len(txt) != maxlen else txt for txt in corpus_tokenized]\n",
    "    \n",
    "## generate idx\n",
    "idx = [tokenizer.convert_tokens_to_ids (seq) for seq in txt2seq]  # I think the problem is here, the tokenizer.encode() seems automatically adding a [CLS] up-front..\n",
    "#idx = [tokenizer.encode(seq.split(\" \")) for seq in txt2seq]    \n",
    "\n",
    "## generate segments\n",
    "segments = [] \n",
    "for seq in txt2seq:\n",
    "    temp, i = [], 0\n",
    "    for token in seq:\n",
    "        temp.append(i)\n",
    "        if token == \"[SEP]\":\n",
    "             i += 1\n",
    "    segments.append(temp)\n",
    "## feature matrix\n",
    "X_test = [np.asarray(idx, dtype='int32'), \n",
    "           np.asarray(masks, dtype='int32'), \n",
    "           np.asarray(segments, dtype='int32')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(df['quality_rank'].values[:4000])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = to_categorical(df['quality_rank'].values[4000:])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup checkpoint\n",
    "\n",
    "checkpoint_path = \"ckpt_distil-bert_embedding/\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model = model) # https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_pathath, max_to_keep=2)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Latest checkpoint restored!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ckpt_manager.save()\n",
    "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 0s - loss: 0.6644 - accuracy: 0.5968 Checkpoint saved at ckpt_distil-bert_embedding/.\n",
      "63/63 [==============================] - 1285s 20s/step - loss: 0.6644 - accuracy: 0.5968 - val_loss: 0.6594 - val_accuracy: 0.5940\n"
     ]
    }
   ],
   "source": [
    "## train\n",
    "training = model.fit(x=X_train, y=y_train, batch_size=64, \n",
    "                     epochs=1, validation_data=(X_test, y_test),\n",
    "                    callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 0s - loss: 0.6467 - accuracy: 0.6248 Checkpoint saved at ckpt_distil-bert_embedding/.\n",
      "63/63 [==============================] - 1280s 20s/step - loss: 0.6467 - accuracy: 0.6248 - val_loss: 0.6491 - val_accuracy: 0.6270\n"
     ]
    }
   ],
   "source": [
    "## train more\n",
    "training = model.fit(x=X_train, y=y_train, batch_size=64, \n",
    "                     epochs=1, validation_data=(X_test, y_test),\n",
    "                    callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6380 - accuracy: 0.6360 Checkpoint saved at ckpt_distil-bert_embedding/.\n",
      "63/63 [==============================] - 1283s 20s/step - loss: 0.6380 - accuracy: 0.6360 - val_loss: 0.6477 - val_accuracy: 0.6240\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6340 - accuracy: 0.6382 Checkpoint saved at ckpt_distil-bert_embedding/.\n",
      "63/63 [==============================] - 1281s 20s/step - loss: 0.6340 - accuracy: 0.6382 - val_loss: 0.6504 - val_accuracy: 0.6320\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6311 - accuracy: 0.6430 Checkpoint saved at ckpt_distil-bert_embedding/.\n",
      "63/63 [==============================] - 1275s 20s/step - loss: 0.6311 - accuracy: 0.6430 - val_loss: 0.6500 - val_accuracy: 0.6270\n"
     ]
    }
   ],
   "source": [
    "## train more\n",
    "training = model.fit(x=X_train, y=y_train, batch_size=64, \n",
    "                     epochs=3, validation_data=(X_test, y_test),\n",
    "                    callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7312715 , 0.2684852 ],\n",
       "       [0.7173048 , 0.30848968],\n",
       "       [0.49267268, 0.5057405 ],\n",
       "       ...,\n",
       "       [0.4282417 , 0.56273687],\n",
       "       [0.5180499 , 0.47388846],\n",
       "       [0.51664007, 0.46902952]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Distil-BERT_dev_prob.csv', pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.595"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - sum(df['quality_rank'][4000:].values) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = [np.argmax(pred) for pred in \n",
    "             pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted))\n",
    "predicted = np.array(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_binary = df['quality_rank'][4000:].values\n",
    "y_test_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.627\n",
      "Auc: 0.564\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.90      0.74       595\n",
      "           1       0.60      0.23      0.34       405\n",
      "\n",
      "    accuracy                           0.63      1000\n",
      "   macro avg       0.62      0.56      0.54      1000\n",
      "weighted avg       0.62      0.63      0.58      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test_binary, predicted)\n",
    "auc = metrics.roc_auc_score(y_test_binary, predicted)  # predicted_prob), check doc, seems the second argument required to be shape (n_samples,) for binary case \n",
    "                            #multi_class=\"ovr\") # check documentation and seems \"ovr\" not good for only binary target class\n",
    "print(\"Accuracy:\",  round(accuracy,3))\n",
    "print(\"Auc:\", round(auc,3))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test_binary, predicted))\n",
    "\n",
    "# Accuracy output 0.627 => align with model performance result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
