{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-for-tf2\n",
      "  Downloading bert-for-tf2-0.14.4.tar.gz (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 1.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting py-params>=0.9.6\n",
      "  Downloading py-params-0.9.7.tar.gz (6.8 kB)\n",
      "Collecting params-flow>=0.8.0\n",
      "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
      "Requirement already satisfied: numpy in /home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.1)\n",
      "Requirement already satisfied: tqdm in /home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.42.1)\n",
      "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
      "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.4-py3-none-any.whl size=30114 sha256=8add6b6b4598d4c300f4814767ee1440b896ccacbd5ae05a428af27aa710a1a0\n",
      "  Stored in directory: /home/nobu_yamaguchi/.cache/pip/wheels/6c/c9/9c/363182ea34a736dae336eeaf0dd4a7eec3c6a5afe32373e1fe\n",
      "  Building wheel for py-params (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-params: filename=py_params-0.9.7-py3-none-any.whl size=7302 sha256=8ac0dcbc968ce8599110cba6d6bb23899f4465fb7eea4584186b35556c449a0a\n",
      "  Stored in directory: /home/nobu_yamaguchi/.cache/pip/wheels/47/3d/2d/bbffcfd6b9f4b8b5cbf07e7520ac2676192fe9431240c13ee8\n",
      "  Building wheel for params-flow (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19473 sha256=db82dd4d94cafc56d4ee6e075c4dc30fc1c29e662d0b70567d39fb5248e18166\n",
      "  Stored in directory: /home/nobu_yamaguchi/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
      "Successfully built bert-for-tf2 py-params params-flow\n",
      "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
      "Successfully installed bert-for-tf2-0.14.4 params-flow-0.8.2 py-params-0.9.7\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/nobu_yamaguchi/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.91\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/nobu_yamaguchi/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.8.0-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 2.7 MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages (from tensorflow_hub) (3.12.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages (from tensorflow_hub) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages (from tensorflow_hub) (1.18.1)\n",
      "Requirement already satisfied: setuptools in /home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow_hub) (45.2.0.post20200210)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.8.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/nobu_yamaguchi/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import numpy as up\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as cPickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_abstract = pd.read_csv('patent_abstract_5000.csv')\n",
    "patent_abstract.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(patent_abstract['radicalness'], density=False)  # `density=False` would make counts\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('radicalness');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33607938642127627"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(patent_abstract.radicalness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "\n",
    "    (patent_abstract['radicalness'] < 0.25),\n",
    "    ((patent_abstract['radicalness'] >= 0.25) & (patent_abstract['radicalness'] < 0.6)),\n",
    "    (patent_abstract['radicalness'] >= 0.6)\n",
    "]\n",
    "\n",
    "choices = ['0', '1', '2']\n",
    "\n",
    "patent_abstract['radicalness_rank'] = np.select(condlist=conditions, choicelist=choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = patent_abstract[['text', 'radicalness_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = []\n",
    "sentences = list(df['text'])\n",
    "for sen in sentences:\n",
    "    abstracts.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text' 'radicalness_rank']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '0', '1'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.radicalness_rank.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2091\n",
       "1    1983\n",
       "2     926\n",
       "Name: radicalness_rank, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.radicalness_rank.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.radicalness_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_abstracts(text_abstracts):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_abstracts = [tokenize_abstracts(abstract) for abstract in abstracts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerparing Data For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_with_len = [[abstract, y[i], len(abstract)]\n",
    "                 for i, abstract in enumerate(tokenized_abstracts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(abstracts_with_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_with_len.sort(key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_abstracts_labels = [(abstract_lab[0], abstract_lab[1]) for abstract_lab in abstracts_with_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_abstracts_labels, output_types=(tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 23), dtype=int32, numpy=\n",
       " array([[ 1037,  8822,  2291,  2005,  2019,  2948,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 4725,  2005,  8225,  1996,  2206,  7328,  2024, 21362,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 1996, 11028, 14623,  2000,  2019, 14794,  9179, 17564,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 1996, 11028, 14623,  2000, 25416, 22648,  7062, 14692,  8670,\n",
       "         18142,  8962,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 4725,  1998,  9265,  3141,  2000, 14126,  6074,  2000, 13656,\n",
       "          8153,  2024,  2649,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 1996, 11028, 14623,  2000, 14692, 11307,  1998,  4118,  2005,\n",
       "          4526, 14692, 11307,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 1037,  2832,  2005,  1996,  7547,  1997,  1996,  7328,  1997,\n",
       "          5675,  2003,  2649,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 1996,  2556, 11028,  3640, 10099,  9265, 21739,  1998,  4725,\n",
       "          1997,  2478,  1996,  2168,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 8331, 15110,  2164, 19706,  5412,  2000,  2022,  8546,  3442,\n",
       "          2240,  2005,  7176,  1996, 19706,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [21362,  2182,  2378,  2024,  6194,  2005,  5716,  6519, 19419,\n",
       "          5648, 16942,  3421,  2011,  5675,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 1996,  2556, 11028, 14623,  2000,  4118,  2005, 17739, 17824,\n",
       "          1051, 10085, 17250,  2030, 17824, 28086,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 1996, 11028, 14623,  2000,  4725,  2005,  5155,  2632, 25383,\n",
       "         18124,  2015,  1998,  1996, 19577,  1998,  7312,  3688, 21739,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 1037,  2606,  2729,  5512,  9605,  2013,  1059,  2102,  2000,\n",
       "          1059,  2102,  1997,  1996,  2561,  5512,  1997, 23431,  5474,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 9265,  1998,  4725,  2005,  1996, 11616,  3949,  1998,  9740,\n",
       "          1997,  9253, 24759, 15396,  1043,  3609, 22471,  2389,  4456,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 1996,  2556, 11028, 14623,  2000, 19782,  2828,  4318,  8808,\n",
       "          2030, 11825,  2833,  4031,  1998,  2000,  2049,  5814,  2832,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [ 1996, 11028,  3640, 22931,  2114, 10882, 12618, 28522,  3367,\n",
       "         13791,  5250,  6904,  2361,  1998,  4725,  1997,  2478,  1996,\n",
       "          2168,     0,     0,     0,     0],\n",
       "        [ 1996, 11028, 14623,  2000,  5080,  2005,  3806, 10808,  1998,\n",
       "         14178,  9031,  2005,  5001, 10464,  9363,  7685,  2478,  8060,\n",
       "         15946,     0,     0,     0,     0],\n",
       "        [ 1037,  6302,  6767, 24458,  2594,  5080,  2064,  2421, 20681,\n",
       "         16888,  2121,  6741,  2007,  5301, 28353, 27759,  2425,  9496,\n",
       "          3207, 10296,     0,     0,     0],\n",
       "        [ 1037, 15026,  3720,  2383, 16305, 15026,  2007,  6741,  1997,\n",
       "         21396, 14876, 12556,  8360, 18898,  1998,  4725,  1997,  2437,\n",
       "          1998,  2478,     0,     0,     0],\n",
       "        [ 1996,  2556, 11028, 14623,  2000,  2047,  3424, 11263, 13807,\n",
       "          2140,  9265,  1998,  2037,  2224,  1999,  1996,  3949,  1997,\n",
       "          4910,  3688,     0,     0,     0],\n",
       "        [ 1996,  2556, 11028, 14623,  2000, 20377,  5051,  6895,  8873,\n",
       "          2278, 22931,  2114,  4647,  2863,  1998,  3729,  2037,  9922,\n",
       "          1998,  2224,     0,     0,     0],\n",
       "        [ 1996,  7107,  4646, 14623,  2000, 22822, 21850,  7229, 16942,\n",
       "          1997,  5675,  2007,  8760, 12353,  1999, 12318,  4319, 22423,\n",
       "          1998, 26641,     0,     0,     0],\n",
       "        [ 1996, 11028,  3640,  3424,  4429, 25032, 22931,  1998, 10047,\n",
       "         23041, 24163,  2078,  9103,  5867,  2015,  1998,  4725,  1997,\n",
       "          2478,  1996,  2168,     0,     0],\n",
       "        [ 1037,  4118,  1998, 14709,  2005, 11737,  6562, 11320, 22311,\n",
       "          2854,  2005,  7497,  1998,  2951,  6726,  1999,  5710,  2422,\n",
       "          4806,  1058, 15472,     0,     0],\n",
       "        [ 1037,  4226,  3560,  7300,  1997,  1996,  8915,  6494, 11368,\n",
       "         29598,  3286, 26387,  5474,  1997, 17770, 14573,  2401,  6844,\n",
       "         27165,  6540,  2917,     0,     0],\n",
       "        [ 1996,  2556, 11028, 14623,  2000,  1996,  2492,  1997,  2966,\n",
       "         16474,  2015,  1998,  2062,  4919,  2000,  8720,  1997,  2572,\n",
       "         27678,  4588,  8331,     0,     0],\n",
       "        [ 1996,  2556, 11028, 14623,  2000, 17492, 16031,  7888,  2164,\n",
       "          3526, 18845,  3366, 16662,  2593,  2894,  2030,  1999,  5257,\n",
       "          2007,  2060,  6039,  2545,     0],\n",
       "        [ 7861,  5092, 21341,  2015,  1997,  1996,  2556, 11028,  3444,\n",
       "          3117,  7987,  7677,  3593,  9265,  4725,  1997,  2437,  1998,\n",
       "          4725,  1997, 12318,  4295,     0],\n",
       "        [ 1996, 11028, 14623,  2000,  2019,  1041, 20614,  2953,  1999,\n",
       "          3327,  2005,  2346, 22491,  3698,  2007,  2029,  1996,  6032,\n",
       "          3947,  2003,  9839, 11038,     0],\n",
       "        [ 3117, 21864,  3630,  4179, 10099,  1997,  5675, 13859,  9265,\n",
       "          4820,  2107, 10099,  1998,  2037,  2224,  1999,  7242,  2004,\n",
       "         22953,  5302,  9527,  8113, 25456],\n",
       "        [ 2122, 11320, 11233, 27654,  6351,  9309,  2031,  2540,  2081,\n",
       "          1997,  6351, 17782,  2594,  6058, 18898,  4820,  2012,  2560,\n",
       "          2028, 11320, 10020,  7361, 16892],\n",
       "        [ 1996, 11028, 14623,  2000, 12509,  8021,  2030, 12509, 19806,\n",
       "          4118,  2005,  5155,  3569, 12379, 28688,  1998,  2000,  4118,\n",
       "          2005,  5814, 22157, 10163,  6046]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 1, 0, 1, 2, 0, 2, 0, 1, 2, 1, 1, 1,\n",
       "        1, 1, 2, 2, 2, 0, 2, 1, 1, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(batched_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_BATCHES = np.math.ceil(len(sorted_abstracts_labels) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 20\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=3,\n",
    "                 dropout_rate=0.2,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=4,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if model_output_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=model_output_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2 = self.cnn_layer2(l) \n",
    "        l_2 = self.pool(l_2)\n",
    "        l_3 = self.cnn_layer3(l)\n",
    "        l_3 = self.pool(l_3) \n",
    "        \n",
    "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "        model_output = self.last_dense(concatenated)\n",
    "        \n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "CNN_FILTERS = 100\n",
    "DNN_UNITS = 256\n",
    "OUTPUT_CLASSES = 3\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "NB_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUTPUT_CLASSES == 2:\n",
    "    text_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"acc\"])\n",
    "else:\n",
    "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 1.0469 - acc: 0.4263\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 0.9541 - acc: 0.5505\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 0.5137 - acc: 0.8088\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 0.0837 - acc: 0.9824\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 0.0152 - acc: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda4c2cdf10>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model.fit(train_data, epochs=NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7/Unknown - 0s 25ms/step - loss: 2.0455 - acc: 0.3393[2.0454530715942383, 0.3392857]\n"
     ]
    }
   ],
   "source": [
    "results = text_model.evaluate(test_data)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
