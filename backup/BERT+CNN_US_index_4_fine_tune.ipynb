{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as up\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "import bert\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as cPickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_quality = pd.read_csv('US_patent_abstract_5000_2015_with_title_1.csv')\n",
    "df_merge_quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merge_quality[['claims_text', 'quality_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2896\n",
       "1    2104\n",
       "Name: quality_rank, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.quality_rank.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5792"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2896/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = []\n",
    "sentences = list(df['claims_text'])\n",
    "for sen in sentences:\n",
    "    claims.append(preprocess_text(str(sen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' device comprising memory to store instructions where the device is first device and processor to execute the instructions to receive first message and second message from second device where the first message and the second message differ and where the first message includes first header and first event data and the second message includes second header and second event data identify based on the first header and the second header that the first message and the second messages are problem reports process in response to identifying the first message and the second messages as the problem reports the first event data to determine that the first event data in the first message is associated with particular reconfiguration information of plurality of reconfiguration information corresponding with the second device process in response to identifying the first message and the second messages as the problem reports the second event data to determine that the second event data in the second message is not associated with any of the plurality of reconfiguration information transmit the particular reconfiguration information to the second device in response to the first message determine additional information based on processing the second event data form based on processing the second event data reformatted second message including the adding additional information to the second message and transmit the second reformatted problem report to third device The device of claim where the processor when processing the first event data is further to identify based on the first event data first type of event that occurred in the second device that led to generation of the first message and determine the reconfiguration information based on the identified first type of event that occurred in the second device The device of claim where the processor when determining the additional information is further to identify based on the second event data second type of event that occurred in the second device that led to generation of the second message and determine the additional information based on the identified second type of event that occurred in the second device The device of claim where the information added to the reformatted second message based on the identified second type of event includes an alert to the third device related to the identified second type of event at the second device The device of claim where the processor when determining the additional information is further to identify the additional information based on an attribute of the third device that receives the reformatted second message The device of claim where the additional information includes an action to be performed by the third device in response to the receiving the reformatted second message The device of claim where the processor when forming the reformatted problem report is further to identify confidential data in the second message and filter out the confidential data in the reformatted second message prior to transmitting the reformatted second message to the third device The device of claim where the reconfiguration information includes at least one of software process or script associated with the second event data method performed by device the method comprising associating one of an action or reconfiguration information with each of plurality of event data types receiving first message from first device where the first message includes first problem report that includes first type of event data of the plurality of event data types where the first type of event data is associated with particular action receiving second message from the first device where the second message includes second problem report that includes second type of event data of the plurality of event data types where the second type of event data is associated with particular reconfiguration information forming third problem report based on the first message where the third problem report includes an indication of the first type of event data from the first report and the particular action associated with the first type of event data from the first message transmitting the third problem report to second device forming fourth problem report based on the second message where the fourth problem report includes an indication of the second type of event data from the second report and the particular reconfiguration information associated with the second type of event data from the second message and transmitting the fourth problem report to the first device The method of claim where forming the third problem report further includes including security information and timestamp information associated with the first message in the third problem report The method of claim where the third problem report includes information to enable the second device to perform the particular action associated with the first type of event data included in the first message The method of claim where the second device is associated with customer intelligence database and where the particular action includes analyzing data from the third problem report and storing the analyzed data from the third problem report in the customer intelligence database The method of claim where the particular action includes determining by the second device another reconfiguration information associated with the first device and the first type of event data from the first message where the reconfiguration information includes at least one of software process or script and forwarding from the second device the other reconfiguration information to the first device The method of claim where the reconfiguration information includes data to correct an event that occurred in the first device where the first type of event data is associated with the event The method of claim where the second device is associated with vendor of the first device non transient memory device comprising instructions executable by processor of device the instructions including one or more instructions to receive first message from downstream device one or more instructions to identify events included in the first message one or more instructions to store and associate at least one of reconfiguration information an action or an alert with an identified event included in the first message one or more instructions to form second message where the second message includes the identified event from the first message and the at least one of the reconfiguration information the action or the alert associated with the identified event one or more instructions to transmit the second message that includes at least one of the action or the alert to an upstream device when there is no reconfiguration information associated with the identified event included in the second message and one or more instructions to transmit the second message to the downstream device when there is reconfiguration information associated with the identified event included in the second message The non transient memory device of claim where the one or more instructions to form second message include one or more instructions to filter out confidential data included in the first message The non transient memory device of claim where the one or more instructions to form second message include one or more instructions to include security information and timestamp information associated with the first message in the second message The non transient memory device of claim where the one or more instructions to transmit the second message include one or more instructions to receive from the upstream device the reconfiguration information and one or more instructions to forward to the downstream device the received reconfiguration information from the upstream device The non transient memory device of claim where the instructions further include one or more instructions to determine the reconfiguration information based on the identified event from the first message '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8033"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(claims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['claims_text' 'quality_rank']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.quality_rank.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for data label\n",
    "data_labels = df.quality_rank.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data_labels[:4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data_labels[4000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2104"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1680 + 424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT tokenizer\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sent, max_seq_length):\n",
    "    if len(sent) <= max_seq_length:\n",
    "        return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]\n",
    "    else: # BERT limited to 512 tokens\n",
    "        return [\"[CLS]\"] + tokenizer.tokenize(sent)[:max_seq_length] + [\"[SEP]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT takes maximum 512 sequence\n",
    "\n",
    "MAX_SEQ_LEN=400\n",
    "\n",
    "tokenized_claims = [encode_sentence(sentence, MAX_SEQ_LEN) for sentence in claims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[CLS]',\n",
       "  'device',\n",
       "  'comprising',\n",
       "  'memory',\n",
       "  'to',\n",
       "  'store',\n",
       "  'instructions',\n",
       "  'where',\n",
       "  'the',\n",
       "  'device',\n",
       "  'is',\n",
       "  'first',\n",
       "  'device',\n",
       "  'and',\n",
       "  'processor',\n",
       "  'to',\n",
       "  'execute',\n",
       "  'the',\n",
       "  'instructions',\n",
       "  'to',\n",
       "  'receive',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'second',\n",
       "  'message',\n",
       "  'from',\n",
       "  'second',\n",
       "  'device',\n",
       "  'where',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'message',\n",
       "  'differ',\n",
       "  'and',\n",
       "  'where',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'includes',\n",
       "  'first',\n",
       "  'header',\n",
       "  'and',\n",
       "  'first',\n",
       "  'event',\n",
       "  'data',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'message',\n",
       "  'includes',\n",
       "  'second',\n",
       "  'header',\n",
       "  'and',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'identify',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'first',\n",
       "  'header',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'header',\n",
       "  'that',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'messages',\n",
       "  'are',\n",
       "  'problem',\n",
       "  'reports',\n",
       "  'process',\n",
       "  'in',\n",
       "  'response',\n",
       "  'to',\n",
       "  'identifying',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'messages',\n",
       "  'as',\n",
       "  'the',\n",
       "  'problem',\n",
       "  'reports',\n",
       "  'the',\n",
       "  'first',\n",
       "  'event',\n",
       "  'data',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'that',\n",
       "  'the',\n",
       "  'first',\n",
       "  'event',\n",
       "  'data',\n",
       "  'in',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'is',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'particular',\n",
       "  'rec',\n",
       "  '##on',\n",
       "  '##fi',\n",
       "  '##gur',\n",
       "  '##ation',\n",
       "  'information',\n",
       "  'of',\n",
       "  'plurality',\n",
       "  'of',\n",
       "  'rec',\n",
       "  '##on',\n",
       "  '##fi',\n",
       "  '##gur',\n",
       "  '##ation',\n",
       "  'information',\n",
       "  'corresponding',\n",
       "  'with',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'process',\n",
       "  'in',\n",
       "  'response',\n",
       "  'to',\n",
       "  'identifying',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'messages',\n",
       "  'as',\n",
       "  'the',\n",
       "  'problem',\n",
       "  'reports',\n",
       "  'the',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'that',\n",
       "  'the',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'message',\n",
       "  'is',\n",
       "  'not',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'any',\n",
       "  'of',\n",
       "  'the',\n",
       "  'plurality',\n",
       "  'of',\n",
       "  'rec',\n",
       "  '##on',\n",
       "  '##fi',\n",
       "  '##gur',\n",
       "  '##ation',\n",
       "  'information',\n",
       "  'transmit',\n",
       "  'the',\n",
       "  'particular',\n",
       "  'rec',\n",
       "  '##on',\n",
       "  '##fi',\n",
       "  '##gur',\n",
       "  '##ation',\n",
       "  'information',\n",
       "  'to',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'in',\n",
       "  'response',\n",
       "  'to',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'determine',\n",
       "  'additional',\n",
       "  'information',\n",
       "  'based',\n",
       "  'on',\n",
       "  'processing',\n",
       "  'the',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'form',\n",
       "  'based',\n",
       "  'on',\n",
       "  'processing',\n",
       "  'the',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'reform',\n",
       "  '##att',\n",
       "  '##ed',\n",
       "  'second',\n",
       "  'message',\n",
       "  'including',\n",
       "  'the',\n",
       "  'adding',\n",
       "  'additional',\n",
       "  'information',\n",
       "  'to',\n",
       "  'the',\n",
       "  'second',\n",
       "  'message',\n",
       "  'and',\n",
       "  'transmit',\n",
       "  'the',\n",
       "  'second',\n",
       "  'reform',\n",
       "  '##att',\n",
       "  '##ed',\n",
       "  'problem',\n",
       "  'report',\n",
       "  'to',\n",
       "  'third',\n",
       "  'device',\n",
       "  'the',\n",
       "  'device',\n",
       "  'of',\n",
       "  'claim',\n",
       "  'where',\n",
       "  'the',\n",
       "  'processor',\n",
       "  'when',\n",
       "  'processing',\n",
       "  'the',\n",
       "  'first',\n",
       "  'event',\n",
       "  'data',\n",
       "  'is',\n",
       "  'further',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'first',\n",
       "  'event',\n",
       "  'data',\n",
       "  'first',\n",
       "  'type',\n",
       "  'of',\n",
       "  'event',\n",
       "  'that',\n",
       "  'occurred',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'that',\n",
       "  'led',\n",
       "  'to',\n",
       "  'generation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'determine',\n",
       "  'the',\n",
       "  'rec',\n",
       "  '##on',\n",
       "  '##fi',\n",
       "  '##gur',\n",
       "  '##ation',\n",
       "  'information',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'identified',\n",
       "  'first',\n",
       "  'type',\n",
       "  'of',\n",
       "  'event',\n",
       "  'that',\n",
       "  'occurred',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'the',\n",
       "  'device',\n",
       "  'of',\n",
       "  'claim',\n",
       "  'where',\n",
       "  'the',\n",
       "  'processor',\n",
       "  'when',\n",
       "  'determining',\n",
       "  'the',\n",
       "  'additional',\n",
       "  'information',\n",
       "  'is',\n",
       "  'further',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'second',\n",
       "  'type',\n",
       "  'of',\n",
       "  'event',\n",
       "  'that',\n",
       "  'occurred',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'that',\n",
       "  'led',\n",
       "  'to',\n",
       "  'generation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'second',\n",
       "  'message',\n",
       "  'and',\n",
       "  'determine',\n",
       "  'the',\n",
       "  'additional',\n",
       "  'information',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'identified',\n",
       "  'second',\n",
       "  'type',\n",
       "  'of',\n",
       "  'event',\n",
       "  'that',\n",
       "  'occurred',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'the',\n",
       "  'device',\n",
       "  'of',\n",
       "  'claim',\n",
       "  'where',\n",
       "  'the',\n",
       "  'information',\n",
       "  'added',\n",
       "  'to',\n",
       "  'the',\n",
       "  'reform',\n",
       "  '##att',\n",
       "  '##ed',\n",
       "  'second',\n",
       "  'message',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'identified',\n",
       "  'second',\n",
       "  'type',\n",
       "  'of',\n",
       "  'event',\n",
       "  'includes',\n",
       "  'an',\n",
       "  'alert',\n",
       "  'to',\n",
       "  'the',\n",
       "  'third',\n",
       "  'device',\n",
       "  'related',\n",
       "  'to',\n",
       "  '[SEP]'],\n",
       " ['[CLS]',\n",
       "  'the',\n",
       "  'invention',\n",
       "  'claimed',\n",
       "  'is',\n",
       "  'control',\n",
       "  'system',\n",
       "  'for',\n",
       "  'an',\n",
       "  'elevator',\n",
       "  'comprising',\n",
       "  'sensor',\n",
       "  'to',\n",
       "  'sense',\n",
       "  'parameter',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'when',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'is',\n",
       "  'moving',\n",
       "  'cal',\n",
       "  '##cula',\n",
       "  '##tor',\n",
       "  'used',\n",
       "  'to',\n",
       "  'calculate',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'to',\n",
       "  'set',\n",
       "  'speed',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'using',\n",
       "  'information',\n",
       "  'from',\n",
       "  'the',\n",
       "  'sensor',\n",
       "  'obtained',\n",
       "  'when',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'is',\n",
       "  'moving',\n",
       "  'memory',\n",
       "  'to',\n",
       "  'store',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'which',\n",
       "  'sets',\n",
       "  'speed',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'and',\n",
       "  'motor',\n",
       "  'controller',\n",
       "  'which',\n",
       "  'controls',\n",
       "  'movement',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'using',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'stored',\n",
       "  'in',\n",
       "  'the',\n",
       "  'memory',\n",
       "  'control',\n",
       "  'system',\n",
       "  'for',\n",
       "  'an',\n",
       "  'elevator',\n",
       "  'according',\n",
       "  'to',\n",
       "  'claim',\n",
       "  'wherein',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'comprises',\n",
       "  'pattern',\n",
       "  'of',\n",
       "  'velocity',\n",
       "  'or',\n",
       "  'pattern',\n",
       "  'of',\n",
       "  'an',\n",
       "  'acceleration',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'control',\n",
       "  'system',\n",
       "  'for',\n",
       "  'an',\n",
       "  'elevator',\n",
       "  'according',\n",
       "  'to',\n",
       "  'claim',\n",
       "  'wherein',\n",
       "  'the',\n",
       "  'cal',\n",
       "  '##cula',\n",
       "  '##tor',\n",
       "  'calculate',\n",
       "  '##s',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'using',\n",
       "  'the',\n",
       "  'information',\n",
       "  'from',\n",
       "  'the',\n",
       "  'sensor',\n",
       "  'which',\n",
       "  'was',\n",
       "  'obtained',\n",
       "  'while',\n",
       "  'carrying',\n",
       "  'load',\n",
       "  'state',\n",
       "  'of',\n",
       "  'car',\n",
       "  'is',\n",
       "  'changed',\n",
       "  'in',\n",
       "  'at',\n",
       "  'least',\n",
       "  'two',\n",
       "  'ways',\n",
       "  'when',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'is',\n",
       "  'installed',\n",
       "  'control',\n",
       "  'system',\n",
       "  'for',\n",
       "  'an',\n",
       "  'elevator',\n",
       "  'according',\n",
       "  'to',\n",
       "  'claim',\n",
       "  'wherein',\n",
       "  'the',\n",
       "  'cal',\n",
       "  '##cula',\n",
       "  '##tor',\n",
       "  'calculate',\n",
       "  '##s',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'using',\n",
       "  'loss',\n",
       "  'during',\n",
       "  'the',\n",
       "  'movement',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'and',\n",
       "  'an',\n",
       "  'efficiency',\n",
       "  'of',\n",
       "  'system',\n",
       "  'control',\n",
       "  'system',\n",
       "  'for',\n",
       "  'an',\n",
       "  'elevator',\n",
       "  'according',\n",
       "  'to',\n",
       "  'claim',\n",
       "  'wherein',\n",
       "  'the',\n",
       "  'cal',\n",
       "  '##cula',\n",
       "  '##tor',\n",
       "  'calculate',\n",
       "  '##s',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'using',\n",
       "  'torque',\n",
       "  'component',\n",
       "  'of',\n",
       "  'motor',\n",
       "  'current',\n",
       "  'or',\n",
       "  'torque',\n",
       "  'command',\n",
       "  'value',\n",
       "  'sensed',\n",
       "  'by',\n",
       "  'the',\n",
       "  'sensor',\n",
       "  'control',\n",
       "  'system',\n",
       "  'for',\n",
       "  'an',\n",
       "  'elevator',\n",
       "  'according',\n",
       "  'to',\n",
       "  'claim',\n",
       "  'wherein',\n",
       "  'the',\n",
       "  'cal',\n",
       "  '##cula',\n",
       "  '##tor',\n",
       "  'calculate',\n",
       "  '##s',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'using',\n",
       "  'sensor',\n",
       "  'information',\n",
       "  'acquired',\n",
       "  'when',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'travels',\n",
       "  'in',\n",
       "  'an',\n",
       "  'empty',\n",
       "  'state',\n",
       "  'control',\n",
       "  'system',\n",
       "  'according',\n",
       "  'to',\n",
       "  'claim',\n",
       "  'wherein',\n",
       "  'the',\n",
       "  'cal',\n",
       "  '##cula',\n",
       "  '##tor',\n",
       "  'calculate',\n",
       "  '##s',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'using',\n",
       "  'model',\n",
       "  'which',\n",
       "  'includes',\n",
       "  'the',\n",
       "  'information',\n",
       "  'from',\n",
       "  'the',\n",
       "  'sensor',\n",
       "  'control',\n",
       "  'system',\n",
       "  'according',\n",
       "  'to',\n",
       "  'claim',\n",
       "  'wherein',\n",
       "  'the',\n",
       "  'sensor',\n",
       "  'is',\n",
       "  'used',\n",
       "  'to',\n",
       "  'sense',\n",
       "  'the',\n",
       "  'parameter',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'when',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'is',\n",
       "  'moving',\n",
       "  'during',\n",
       "  'testing',\n",
       "  'period',\n",
       "  'control',\n",
       "  'system',\n",
       "  'according',\n",
       "  'to',\n",
       "  'claim',\n",
       "  'wherein',\n",
       "  'the',\n",
       "  'motor',\n",
       "  'controller',\n",
       "  'controls',\n",
       "  'movement',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'using',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'and',\n",
       "  'load',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'control',\n",
       "  'system',\n",
       "  'according',\n",
       "  'to',\n",
       "  'claim',\n",
       "  'wherein',\n",
       "  'the',\n",
       "  'cal',\n",
       "  '##cula',\n",
       "  '##tor',\n",
       "  'calculate',\n",
       "  '##s',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  'using',\n",
       "  'the',\n",
       "  'information',\n",
       "  'from',\n",
       "  'the',\n",
       "  'sensor',\n",
       "  'obtained',\n",
       "  'when',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'is',\n",
       "  'moving',\n",
       "  'under',\n",
       "  'control',\n",
       "  'of',\n",
       "  'the',\n",
       "  'motor',\n",
       "  'controller',\n",
       "  'which',\n",
       "  'is',\n",
       "  'operating',\n",
       "  'using',\n",
       "  'another',\n",
       "  'speed',\n",
       "  'pattern',\n",
       "  '[SEP]']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_claims[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_claims[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepre the 3 inputs required by BERT deriving from the original data\n",
    "\n",
    "def get_ids(tokens):\n",
    "    return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def get_mask(tokens):\n",
    "    return np.char.not_equal(tokens, \"[PAD]\").astype(int)  # if not equal [PAD] then assign 1. \n",
    "\n",
    "def get_segments(tokens):\n",
    "    seg_ids = []\n",
    "    current_seg_id = 0\n",
    "    for tok in tokens:\n",
    "        seg_ids.append(current_seg_id)\n",
    "        if tok == \"[SEP]\":\n",
    "            current_seg_id = 1-current_seg_id # turns 1 into 0 and vice versa\n",
    "    return seg_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below to create padded batches (so there could have different sentence length between batches, but will be same sentence length within batch) this is to save processing memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_len = [[sent, data_labels[i], len(sent)]\n",
    "                 for i, sent in enumerate(tokenized_claims)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train and test\n",
    "\n",
    "data_with_len_train = data_with_len[:4000]\n",
    "data_with_len_test = data_with_len[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[CLS]',\n",
       "  'device',\n",
       "  'comprising',\n",
       "  'memory',\n",
       "  'to',\n",
       "  'store',\n",
       "  'instructions',\n",
       "  'where',\n",
       "  'the',\n",
       "  'device',\n",
       "  'is',\n",
       "  'first',\n",
       "  'device',\n",
       "  'and',\n",
       "  'processor',\n",
       "  'to',\n",
       "  'execute',\n",
       "  'the',\n",
       "  'instructions',\n",
       "  'to',\n",
       "  'receive',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'second',\n",
       "  'message',\n",
       "  'from',\n",
       "  'second',\n",
       "  'device',\n",
       "  'where',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'message',\n",
       "  'differ',\n",
       "  'and',\n",
       "  'where',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'includes',\n",
       "  'first',\n",
       "  'header',\n",
       "  'and',\n",
       "  'first',\n",
       "  'event',\n",
       "  'data',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'message',\n",
       "  'includes',\n",
       "  'second',\n",
       "  'header',\n",
       "  'and',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'identify',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'first',\n",
       "  'header',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'header',\n",
       "  'that',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'messages',\n",
       "  'are',\n",
       "  'problem',\n",
       "  'reports',\n",
       "  'process',\n",
       "  'in',\n",
       "  'response',\n",
       "  'to',\n",
       "  'identifying',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'messages',\n",
       "  'as',\n",
       "  'the',\n",
       "  'problem',\n",
       "  'reports',\n",
       "  'the',\n",
       "  'first',\n",
       "  'event',\n",
       "  'data',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'that',\n",
       "  'the',\n",
       "  'first',\n",
       "  'event',\n",
       "  'data',\n",
       "  'in',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'is',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'particular',\n",
       "  'rec',\n",
       "  '##on',\n",
       "  '##fi',\n",
       "  '##gur',\n",
       "  '##ation',\n",
       "  'information',\n",
       "  'of',\n",
       "  'plurality',\n",
       "  'of',\n",
       "  'rec',\n",
       "  '##on',\n",
       "  '##fi',\n",
       "  '##gur',\n",
       "  '##ation',\n",
       "  'information',\n",
       "  'corresponding',\n",
       "  'with',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'process',\n",
       "  'in',\n",
       "  'response',\n",
       "  'to',\n",
       "  'identifying',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'messages',\n",
       "  'as',\n",
       "  'the',\n",
       "  'problem',\n",
       "  'reports',\n",
       "  'the',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'that',\n",
       "  'the',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'message',\n",
       "  'is',\n",
       "  'not',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'any',\n",
       "  'of',\n",
       "  'the',\n",
       "  'plurality',\n",
       "  'of',\n",
       "  'rec',\n",
       "  '##on',\n",
       "  '##fi',\n",
       "  '##gur',\n",
       "  '##ation',\n",
       "  'information',\n",
       "  'transmit',\n",
       "  'the',\n",
       "  'particular',\n",
       "  'rec',\n",
       "  '##on',\n",
       "  '##fi',\n",
       "  '##gur',\n",
       "  '##ation',\n",
       "  'information',\n",
       "  'to',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'in',\n",
       "  'response',\n",
       "  'to',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'determine',\n",
       "  'additional',\n",
       "  'information',\n",
       "  'based',\n",
       "  'on',\n",
       "  'processing',\n",
       "  'the',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'form',\n",
       "  'based',\n",
       "  'on',\n",
       "  'processing',\n",
       "  'the',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'reform',\n",
       "  '##att',\n",
       "  '##ed',\n",
       "  'second',\n",
       "  'message',\n",
       "  'including',\n",
       "  'the',\n",
       "  'adding',\n",
       "  'additional',\n",
       "  'information',\n",
       "  'to',\n",
       "  'the',\n",
       "  'second',\n",
       "  'message',\n",
       "  'and',\n",
       "  'transmit',\n",
       "  'the',\n",
       "  'second',\n",
       "  'reform',\n",
       "  '##att',\n",
       "  '##ed',\n",
       "  'problem',\n",
       "  'report',\n",
       "  'to',\n",
       "  'third',\n",
       "  'device',\n",
       "  'the',\n",
       "  'device',\n",
       "  'of',\n",
       "  'claim',\n",
       "  'where',\n",
       "  'the',\n",
       "  'processor',\n",
       "  'when',\n",
       "  'processing',\n",
       "  'the',\n",
       "  'first',\n",
       "  'event',\n",
       "  'data',\n",
       "  'is',\n",
       "  'further',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'first',\n",
       "  'event',\n",
       "  'data',\n",
       "  'first',\n",
       "  'type',\n",
       "  'of',\n",
       "  'event',\n",
       "  'that',\n",
       "  'occurred',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'that',\n",
       "  'led',\n",
       "  'to',\n",
       "  'generation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'first',\n",
       "  'message',\n",
       "  'and',\n",
       "  'determine',\n",
       "  'the',\n",
       "  'rec',\n",
       "  '##on',\n",
       "  '##fi',\n",
       "  '##gur',\n",
       "  '##ation',\n",
       "  'information',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'identified',\n",
       "  'first',\n",
       "  'type',\n",
       "  'of',\n",
       "  'event',\n",
       "  'that',\n",
       "  'occurred',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'the',\n",
       "  'device',\n",
       "  'of',\n",
       "  'claim',\n",
       "  'where',\n",
       "  'the',\n",
       "  'processor',\n",
       "  'when',\n",
       "  'determining',\n",
       "  'the',\n",
       "  'additional',\n",
       "  'information',\n",
       "  'is',\n",
       "  'further',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'second',\n",
       "  'event',\n",
       "  'data',\n",
       "  'second',\n",
       "  'type',\n",
       "  'of',\n",
       "  'event',\n",
       "  'that',\n",
       "  'occurred',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'that',\n",
       "  'led',\n",
       "  'to',\n",
       "  'generation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'second',\n",
       "  'message',\n",
       "  'and',\n",
       "  'determine',\n",
       "  'the',\n",
       "  'additional',\n",
       "  'information',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'identified',\n",
       "  'second',\n",
       "  'type',\n",
       "  'of',\n",
       "  'event',\n",
       "  'that',\n",
       "  'occurred',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'device',\n",
       "  'the',\n",
       "  'device',\n",
       "  'of',\n",
       "  'claim',\n",
       "  'where',\n",
       "  'the',\n",
       "  'information',\n",
       "  'added',\n",
       "  'to',\n",
       "  'the',\n",
       "  'reform',\n",
       "  '##att',\n",
       "  '##ed',\n",
       "  'second',\n",
       "  'message',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'identified',\n",
       "  'second',\n",
       "  'type',\n",
       "  'of',\n",
       "  'event',\n",
       "  'includes',\n",
       "  'an',\n",
       "  'alert',\n",
       "  'to',\n",
       "  'the',\n",
       "  'third',\n",
       "  'device',\n",
       "  'related',\n",
       "  'to',\n",
       "  '[SEP]'],\n",
       " 0,\n",
       " 402]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_len_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_with_len_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([402, 352, 402, ..., 402, 402, 402], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the sentence length\n",
    "np.array(data_with_len_train)[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([22, 47, 50, 69, 84, 89, 95, 99, 100, 108, 112, 116, 117, 118, 131,\n",
       "        132, 136, 137, 141, 142, 143, 144, 147, 148, 150, 155, 159, 160,\n",
       "        162, 164, 165, 168, 173, 174, 175, 176, 178, 180, 181, 182, 184,\n",
       "        185, 186, 187, 188, 191, 193, 194, 195, 196, 197, 198, 199, 201,\n",
       "        202, 203, 205, 206, 207, 208, 209, 212, 213, 215, 216, 217, 219,\n",
       "        220, 222, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235,\n",
       "        237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
       "        251, 254, 255, 256, 259, 260, 261, 262, 264, 265, 267, 268, 269,\n",
       "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284,\n",
       "        286, 287, 288, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300,\n",
       "        301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314,\n",
       "        316, 318, 320, 321, 322, 323, 324, 326, 327, 328, 329, 331, 332,\n",
       "        333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345,\n",
       "        346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358,\n",
       "        359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373,\n",
       "        374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 386, 387,\n",
       "        389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402],\n",
       "       dtype=object),\n",
       " array([   1,    1,    1,    1,    1,    1,    1,    2,    1,    1,    1,\n",
       "           1,    2,    2,    1,    2,    1,    1,    2,    1,    2,    3,\n",
       "           2,    1,    1,    1,    1,    1,    1,    2,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    2,    1,    2,    1,    2,    3,\n",
       "           1,    2,    2,    1,    1,    1,    2,    1,    2,    2,    2,\n",
       "           1,    3,    1,    2,    2,    2,    1,    3,    1,    3,    1,\n",
       "           1,    4,    3,    1,    3,    2,    1,    1,    1,    2,    2,\n",
       "           1,    1,    4,    3,    1,    2,    1,    1,    1,    1,    2,\n",
       "           3,    3,    2,    2,    1,    3,    1,    1,    1,    1,    2,\n",
       "           1,    3,    3,    1,    1,    1,    5,    3,    1,    3,    2,\n",
       "           2,    1,    1,    3,    1,    1,    1,    3,    2,    2,    1,\n",
       "           3,    3,    4,    5,    2,    1,    1,    1,    3,    1,    1,\n",
       "           2,    5,    3,    2,    2,    2,    3,    1,    2,    2,    2,\n",
       "           1,    4,    2,    3,    3,    2,    4,    2,    1,    2,    3,\n",
       "           2,    3,    2,    1,    3,    3,    1,    1,    3,    3,    2,\n",
       "           5,    1,    2,    2,    1,    1,    2,    1,    3,    6,    3,\n",
       "           2,    4,    2,    4,    3,    4,    5,    2,    3,    4,    4,\n",
       "           3,    4,    1,    1,    4,    2,    4,    2,    3,    3,    3,\n",
       "           3,    2,    2,    3,    2,    1,    3,    3,    3,    5,    3,\n",
       "           3,    3,    2,    3,    4,    1,    2,    3,    5,    3,    3,\n",
       "           1,    5, 3539]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(data_with_len_train)[:, 2], return_counts = True)\n",
    "# majority are in 512 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_batch(data_with_len, BATCH_SIZE):\n",
    "    data_with_len = sorted(data_with_len, key=lambda x: x[2])\n",
    "    sorted_all = [([get_ids(sent_lab[0]),\n",
    "                get_mask(sent_lab[0]),\n",
    "                get_segments(sent_lab[0])],\n",
    "               sent_lab[1])\n",
    "              for sent_lab in data_with_len] \n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
    "                                             output_types=(tf.int32, tf.int32))\n",
    "    \n",
    "\n",
    "    train_batched = train_dataset.padded_batch(BATCH_SIZE, # this is the pre-processed input to feed into BERT embedding layer and DCNN model\n",
    "                                       padded_shapes=((3, None), ()),\n",
    "                                       padding_values=(0, 0))\n",
    "    return train_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batched = to_batch(data_with_len_train, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 3, 147), dtype=int32, numpy=\n",
       " array([[[  101,  2054,  2003, ...,     0,     0,     0],\n",
       "         [    1,     1,     1, ...,     0,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  2019,  7275, ...,     0,     0,     0],\n",
       "         [    1,     1,     1, ...,     0,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  1045,  4366, ...,     0,     0,     0],\n",
       "         [    1,     1,     1, ...,     0,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  101,  2054,  2003, ...,     0,     0,     0],\n",
       "         [    1,     1,     1, ...,     0,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  1996, 11028, ...,  8945,  4948,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  1996, 11028, ...,  2003, 25476,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_batched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the batches for evaluation set:\n",
    "test_batched = to_batch(data_with_len_test, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 3, 256), dtype=int32, numpy=\n",
       " array([[[  101, 23767,  2278, ...,     0,     0,     0],\n",
       "         [    1,     1,     1, ...,     0,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  1996, 11028, ...,     0,     0,     0],\n",
       "         [    1,     1,     1, ...,     0,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  4118,  2005, ...,     0,     0,     0],\n",
       "         [    1,     1,     1, ...,     0,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  101,  1996, 11028, ...,     0,     0,     0],\n",
       "         [    1,     1,     1, ...,     0,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  2054,  2003, ...,     0,     0,     0],\n",
       "         [    1,     1,     1, ...,     0,     0,     0],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  1996, 11028, ...,  1996,  6381,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_batched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Count:1000, Positive Label Count:424, Positive Class Ratio:0.424, Negative Class Ratio = 0.5760000000000001\n"
     ]
    }
   ],
   "source": [
    "# double check the label distribution\n",
    "# Validation set\n",
    "count = 0\n",
    "sum_positive = 0\n",
    "for element in test_batched:\n",
    "    count += len(element[1])\n",
    "    sum_positive += sum(element[1])\n",
    "\n",
    "print(f'Sample Count:{count}, Positive Label Count:{sum_positive}, Positive Class Ratio:{sum_positive/count}, Negative Class Ratio = {1-sum_positive/count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Count:4000, Positive Label Count:1680, Positive Class Ratio:0.42, Negative Class Ratio = 0.5800000000000001\n"
     ]
    }
   ],
   "source": [
    "# double check the label distribution\n",
    "# Train set\n",
    "count = 0\n",
    "sum_positive = 0\n",
    "for element in train_batched:\n",
    "    count += len(element[1])\n",
    "    sum_positive += sum(element[1])\n",
    "\n",
    "print(f'Sample Count:{count}, Positive Label Count:{sum_positive}, Positive Class Ratio:{sum_positive/count}, Negative Class Ratio = {1-sum_positive/count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCNNBERTEmbedding(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 nb_filters=50,\n",
    "                 FFN_units=512,\n",
    "                 nb_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 name=\"dcnn\"):\n",
    "        super(DCNNBERTEmbedding, self).__init__(name=name)\n",
    "        \n",
    "        self.bert_layer = hub.KerasLayer(\n",
    "            \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "            trainable=True)\n",
    "\n",
    "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
    "                                    kernel_size=5,\n",
    "                                    padding=\"valid\",\n",
    "                                    activation=\"relu\")\n",
    "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
    "                                     kernel_size=50,\n",
    "                                     padding=\"valid\",\n",
    "                                     activation=\"relu\")\n",
    "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
    "                                      kernel_size=100,\n",
    "                                      padding=\"valid\",\n",
    "                                      activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if nb_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=nb_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def embed_with_bert(self, all_tokens):\n",
    "        _, embs = self.bert_layer([all_tokens[:, 0, :],\n",
    "                                   all_tokens[:, 1, :],\n",
    "                                   all_tokens[:, 2, :]])\n",
    "        return embs\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.embed_with_bert(inputs)\n",
    "\n",
    "        x_1 = self.bigram(x)\n",
    "        x_1 = self.pool(x_1)\n",
    "        x_2 = self.trigram(x)\n",
    "        x_2 = self.pool(x_2)\n",
    "        x_3 = self.fourgram(x)\n",
    "        x_3 = self.pool(x_3)\n",
    "        \n",
    "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_FILTERS = 80\n",
    "FFN_UNITS = 120\n",
    "NB_CLASSES = 2\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NB_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dcnn = DCNNBERTEmbedding(nb_filters=NB_FILTERS,\n",
    "                         FFN_units=FFN_UNITS,\n",
    "                         nb_classes=NB_CLASSES,\n",
    "                         dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NB_CLASSES == 2:\n",
    "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "else:\n",
    "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"ckpt_bert_embedding_fine_tune/\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=2)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Latest checkpoint restored!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ckpt_manager.save()\n",
    "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "    125/Unknown - 4127s 33s/step - loss: 0.9938 - accuracy: 0.5422Checkpoint saved at ckpt_bert_embedding_fine_tune/.\n",
      "125/125 [==============================] - 4507s 36s/step - loss: 0.9938 - accuracy: 0.5422 - val_loss: 0.6835 - val_accuracy: 0.5760\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6904 - accuracy: 0.5508 Checkpoint saved at ckpt_bert_embedding_fine_tune/.\n",
      "125/125 [==============================] - 4530s 36s/step - loss: 0.6904 - accuracy: 0.5508 - val_loss: 0.6816 - val_accuracy: 0.5760\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6830 - accuracy: 0.5778 Checkpoint saved at ckpt_bert_embedding_fine_tune/.\n",
      "125/125 [==============================] - 4487s 36s/step - loss: 0.6830 - accuracy: 0.5778 - val_loss: 0.6817 - val_accuracy: 0.5760\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.5795 Checkpoint saved at ckpt_bert_embedding_fine_tune/.\n",
      "125/125 [==============================] - 4499s 36s/step - loss: 0.6844 - accuracy: 0.5795 - val_loss: 0.6818 - val_accuracy: 0.5760\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6977 - accuracy: 0.5700 Checkpoint saved at ckpt_bert_embedding_fine_tune/.\n",
      "125/125 [==============================] - 4504s 36s/step - loss: 0.6977 - accuracy: 0.5700 - val_loss: 0.6817 - val_accuracy: 0.5760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f411fa3ed90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting time\n",
    "Dcnn.fit(train_batched,\n",
    "         validation_data = (test_batched),\n",
    "         epochs=NB_EPOCHS,\n",
    "         callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "    125/Unknown - 3842s 31s/step - loss: 0.2873 - accuracy: 0.8870Checkpoint saved at ckpt_bert_embedding/.\n",
      "125/125 [==============================] - 4698s 38s/step - loss: 0.2873 - accuracy: 0.8870 - val_loss: 1.4047 - val_accuracy: 0.4770\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.8242 Checkpoint saved at ckpt_bert_embedding/.\n",
      "125/125 [==============================] - 4587s 37s/step - loss: 0.4091 - accuracy: 0.8242 - val_loss: 0.7564 - val_accuracy: 0.5950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa65754c710>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to train more => re-start from the 4th epoch \n",
    "# fitting time\n",
    "Dcnn.fit(train_batched,\n",
    "         validation_data = (test_batched),\n",
    "         epochs=2,\n",
    "         callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "    125/Unknown - 3744s 30s/step - loss: 0.3938 - accuracy: 0.8142Checkpoint saved at ckpt_bert_embedding/.\n",
      "125/125 [==============================] - 4566s 37s/step - loss: 0.3938 - accuracy: 0.8142 - val_loss: 0.7442 - val_accuracy: 0.6140\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.9105 Checkpoint saved at ckpt_bert_embedding/.\n",
      "125/125 [==============================] - 4581s 37s/step - loss: 0.2196 - accuracy: 0.9105 - val_loss: 0.9071 - val_accuracy: 0.6130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb96cd61f10>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-start the training again, from epoch 6\n",
    "Dcnn.fit(train_batched,\n",
    "         validation_data = (test_batched),\n",
    "         epochs=2,\n",
    "         callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 837s 26s/step - loss: 0.9071 - accuracy: 0.6130\n",
      "[0.9070994853973389, 0.6129999756813049]\n"
     ]
    }
   ],
   "source": [
    "results = Dcnn.evaluate(test_batched)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
