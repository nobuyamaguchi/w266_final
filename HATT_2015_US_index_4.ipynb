{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-storage\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep only quality_index_6 >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 30)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_quality = pd.read_csv('US_patent_abstract_5000_2015_with_title_1.csv')\n",
    "df_merge_quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117351596366192"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_merge_quality['quality_index_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0212197159565581"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_merge_quality['quality_index_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_merge_quality['quality_index_4'], density=False)  # `density=False` would make counts\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Quality_Index_4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>publication_number</th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>title_text</th>\n",
       "      <th>claims_text</th>\n",
       "      <th>publication_number_match</th>\n",
       "      <th>appln_id</th>\n",
       "      <th>pub_nbr</th>\n",
       "      <th>filing</th>\n",
       "      <th>...</th>\n",
       "      <th>fwd_cits7</th>\n",
       "      <th>breakthrough</th>\n",
       "      <th>generality</th>\n",
       "      <th>originality</th>\n",
       "      <th>radicalness</th>\n",
       "      <th>renewal</th>\n",
       "      <th>quality_index_4</th>\n",
       "      <th>quality_index_6</th>\n",
       "      <th>quality_rank</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54639</td>\n",
       "      <td>US-8014303-B2</td>\n",
       "      <td>A network device may include logic configured ...</td>\n",
       "      <td>20101229</td>\n",
       "      <td>Systems and methods for interfacing with netwo...</td>\n",
       "      <td>1. A device comprising:\\n memory to store inst...</td>\n",
       "      <td>US08014303</td>\n",
       "      <td>333595253</td>\n",
       "      <td>US08014303</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.751486</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.250936</td>\n",
       "      <td>0.326616</td>\n",
       "      <td>0</td>\n",
       "      <td>Systems and methods for interfacing with netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45032</td>\n",
       "      <td>US-9114955-B2</td>\n",
       "      <td>Provided is a control device for an elevator t...</td>\n",
       "      <td>20101208</td>\n",
       "      <td>Control device for elevator</td>\n",
       "      <td>The invention claimed is: \\n     \\n       1. A...</td>\n",
       "      <td>US09114955</td>\n",
       "      <td>380228413</td>\n",
       "      <td>US09114955</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.619062</td>\n",
       "      <td>0.279297</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.315645</td>\n",
       "      <td>0.289177</td>\n",
       "      <td>1</td>\n",
       "      <td>Control device for elevator. Provided is a con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49357</td>\n",
       "      <td>US-8737855-B2</td>\n",
       "      <td>A plurality of test patches each including a d...</td>\n",
       "      <td>20100927</td>\n",
       "      <td>Image forming apparatus and density unevenness...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. An imag...</td>\n",
       "      <td>US08737855</td>\n",
       "      <td>333087673</td>\n",
       "      <td>US08737855</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499528</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.254967</td>\n",
       "      <td>0.250367</td>\n",
       "      <td>0</td>\n",
       "      <td>Image forming apparatus and density unevenness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151718</td>\n",
       "      <td>US-8531163-B2</td>\n",
       "      <td>To provide a switching power supply device, an...</td>\n",
       "      <td>20100312</td>\n",
       "      <td>Switching power supply device, integrated circ...</td>\n",
       "      <td>The invention claimed is: \\n     \\n       1. A...</td>\n",
       "      <td>US08531163</td>\n",
       "      <td>341889903</td>\n",
       "      <td>US08531163</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713139</td>\n",
       "      <td>0.830487</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.324680</td>\n",
       "      <td>0.317031</td>\n",
       "      <td>1</td>\n",
       "      <td>Switching power supply device, integrated circ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102001</td>\n",
       "      <td>US-9626390-B2</td>\n",
       "      <td>In one general aspect, a computer system can i...</td>\n",
       "      <td>20101227</td>\n",
       "      <td>Shadow system start during upgrade of an origi...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A compu...</td>\n",
       "      <td>US09626390</td>\n",
       "      <td>364671666</td>\n",
       "      <td>US09626390</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786048</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.135417</td>\n",
       "      <td>0.172861</td>\n",
       "      <td>0</td>\n",
       "      <td>Shadow system start during upgrade of an origi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>89503</td>\n",
       "      <td>US-8815989-B2</td>\n",
       "      <td>The invention aims to provide a resin composit...</td>\n",
       "      <td>20101110</td>\n",
       "      <td>Resin composition for coating material</td>\n",
       "      <td>The invention claimed is: \\n     \\n       1. A...</td>\n",
       "      <td>US08815989</td>\n",
       "      <td>376848395</td>\n",
       "      <td>US08815989</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.674311</td>\n",
       "      <td>0.943568</td>\n",
       "      <td>0.471910</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.325126</td>\n",
       "      <td>0.318887</td>\n",
       "      <td>1</td>\n",
       "      <td>Resin composition for coating material. The in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>42696</td>\n",
       "      <td>US-8704454-B2</td>\n",
       "      <td>A method includes forming one or more capacito...</td>\n",
       "      <td>20101013</td>\n",
       "      <td>Integrated driver system architecture for ligh...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A metho...</td>\n",
       "      <td>US08704454</td>\n",
       "      <td>333369342</td>\n",
       "      <td>US08704454</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.592089</td>\n",
       "      <td>0.932416</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.308532</td>\n",
       "      <td>0.309862</td>\n",
       "      <td>1</td>\n",
       "      <td>Integrated driver system architecture for ligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>105030</td>\n",
       "      <td>US-8809921-B2</td>\n",
       "      <td>A solid-state imaging apparatus includes a plu...</td>\n",
       "      <td>20101222</td>\n",
       "      <td>Solid-state imaging apparatus, method of manuf...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A solid...</td>\n",
       "      <td>US08809921</td>\n",
       "      <td>335867166</td>\n",
       "      <td>US08809921</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485926</td>\n",
       "      <td>0.723776</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.298260</td>\n",
       "      <td>0.294224</td>\n",
       "      <td>0</td>\n",
       "      <td>Solid-state imaging apparatus, method of manuf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>171202</td>\n",
       "      <td>US-9149407-B2</td>\n",
       "      <td>A device for therapeutically treating and/or t...</td>\n",
       "      <td>20100521</td>\n",
       "      <td>Device for therapeutically treating and/or tra...</td>\n",
       "      <td>The invention claimed is: \\n     \\n       1. A...</td>\n",
       "      <td>US09149407</td>\n",
       "      <td>353322751</td>\n",
       "      <td>US09149407</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.284082</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.362534</td>\n",
       "      <td>0.304468</td>\n",
       "      <td>1</td>\n",
       "      <td>Device for therapeutically treating and/or tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>158355</td>\n",
       "      <td>US-8971214-B2</td>\n",
       "      <td>A method and apparatus for acquiring a Traffic...</td>\n",
       "      <td>20100424</td>\n",
       "      <td>Method and apparatus for acquiring traffic-eng...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A metho...</td>\n",
       "      <td>US08971214</td>\n",
       "      <td>376846678</td>\n",
       "      <td>US08971214</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486250</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.075490</td>\n",
       "      <td>0.123676</td>\n",
       "      <td>0</td>\n",
       "      <td>Method and apparatus for acquiring traffic-eng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 publication_number  \\\n",
       "0          54639      US-8014303-B2   \n",
       "1          45032      US-9114955-B2   \n",
       "2          49357      US-8737855-B2   \n",
       "3         151718      US-8531163-B2   \n",
       "4         102001      US-9626390-B2   \n",
       "...          ...                ...   \n",
       "4995       89503      US-8815989-B2   \n",
       "4996       42696      US-8704454-B2   \n",
       "4997      105030      US-8809921-B2   \n",
       "4998      171202      US-9149407-B2   \n",
       "4999      158355      US-8971214-B2   \n",
       "\n",
       "                                          abstract_text  filing_date  \\\n",
       "0     A network device may include logic configured ...     20101229   \n",
       "1     Provided is a control device for an elevator t...     20101208   \n",
       "2     A plurality of test patches each including a d...     20100927   \n",
       "3     To provide a switching power supply device, an...     20100312   \n",
       "4     In one general aspect, a computer system can i...     20101227   \n",
       "...                                                 ...          ...   \n",
       "4995  The invention aims to provide a resin composit...     20101110   \n",
       "4996  A method includes forming one or more capacito...     20101013   \n",
       "4997  A solid-state imaging apparatus includes a plu...     20101222   \n",
       "4998  A device for therapeutically treating and/or t...     20100521   \n",
       "4999  A method and apparatus for acquiring a Traffic...     20100424   \n",
       "\n",
       "                                             title_text  \\\n",
       "0     Systems and methods for interfacing with netwo...   \n",
       "1                           Control device for elevator   \n",
       "2     Image forming apparatus and density unevenness...   \n",
       "3     Switching power supply device, integrated circ...   \n",
       "4     Shadow system start during upgrade of an origi...   \n",
       "...                                                 ...   \n",
       "4995             Resin composition for coating material   \n",
       "4996  Integrated driver system architecture for ligh...   \n",
       "4997  Solid-state imaging apparatus, method of manuf...   \n",
       "4998  Device for therapeutically treating and/or tra...   \n",
       "4999  Method and apparatus for acquiring traffic-eng...   \n",
       "\n",
       "                                            claims_text  \\\n",
       "0     1. A device comprising:\\n memory to store inst...   \n",
       "1     The invention claimed is: \\n     \\n       1. A...   \n",
       "2     What is claimed is: \\n     \\n       1. An imag...   \n",
       "3     The invention claimed is: \\n     \\n       1. A...   \n",
       "4     What is claimed is: \\n     \\n       1. A compu...   \n",
       "...                                                 ...   \n",
       "4995  The invention claimed is: \\n     \\n       1. A...   \n",
       "4996  What is claimed is: \\n     \\n       1. A metho...   \n",
       "4997  What is claimed is: \\n     \\n       1. A solid...   \n",
       "4998  The invention claimed is: \\n     \\n       1. A...   \n",
       "4999  What is claimed is: \\n     \\n       1. A metho...   \n",
       "\n",
       "     publication_number_match   appln_id     pub_nbr  filing  ...  fwd_cits7  \\\n",
       "0                  US08014303  333595253  US08014303    2010  ...          3   \n",
       "1                  US09114955  380228413  US09114955    2010  ...          4   \n",
       "2                  US08737855  333087673  US08737855    2010  ...          9   \n",
       "3                  US08531163  341889903  US08531163    2010  ...         15   \n",
       "4                  US09626390  364671666  US09626390    2010  ...          9   \n",
       "...                       ...        ...         ...     ...  ...        ...   \n",
       "4995               US08815989  376848395  US08815989    2010  ...          5   \n",
       "4996               US08704454  333369342  US08704454    2010  ...          3   \n",
       "4997               US08809921  335867166  US08809921    2010  ...          6   \n",
       "4998               US09149407  353322751  US09149407    2010  ...          6   \n",
       "4999               US08971214  376846678  US08971214    2010  ...          3   \n",
       "\n",
       "      breakthrough  generality  originality  radicalness  renewal  \\\n",
       "0                0    0.593750     0.751486     0.137931      5.0   \n",
       "1                0    0.619062     0.279297     0.093750      5.0   \n",
       "2                0    0.499528     0.805556     0.583333      4.0   \n",
       "3                0    0.713139     0.830487     0.755102      7.0   \n",
       "4                0    0.000000     0.786048     0.072000      7.0   \n",
       "...            ...         ...          ...          ...      ...   \n",
       "4995             0    0.674311     0.943568     0.471910      4.0   \n",
       "4996             0    0.592089     0.932416     0.776699      4.0   \n",
       "4997             0    0.485926     0.723776     0.390244      4.0   \n",
       "4998             0    0.284082     0.862222     0.120000      5.0   \n",
       "4999             0    0.000000     0.486250     0.225000      5.0   \n",
       "\n",
       "      quality_index_4  quality_index_6  quality_rank  \\\n",
       "0            0.250936         0.326616             0   \n",
       "1            0.315645         0.289177             1   \n",
       "2            0.254967         0.250367             0   \n",
       "3            0.324680         0.317031             1   \n",
       "4            0.135417         0.172861             0   \n",
       "...               ...              ...           ...   \n",
       "4995         0.325126         0.318887             1   \n",
       "4996         0.308532         0.309862             1   \n",
       "4997         0.298260         0.294224             0   \n",
       "4998         0.362534         0.304468             1   \n",
       "4999         0.075490         0.123676             0   \n",
       "\n",
       "                                                   text  \n",
       "0     Systems and methods for interfacing with netwo...  \n",
       "1     Control device for elevator. Provided is a con...  \n",
       "2     Image forming apparatus and density unevenness...  \n",
       "3     Switching power supply device, integrated circ...  \n",
       "4     Shadow system start during upgrade of an origi...  \n",
       "...                                                 ...  \n",
       "4995  Resin composition for coating material. The in...  \n",
       "4996  Integrated driver system architecture for ligh...  \n",
       "4997  Solid-state imaging apparatus, method of manuf...  \n",
       "4998  Device for therapeutically treating and/or tra...  \n",
       "4999  Method and apparatus for acquiring traffic-eng...  \n",
       "\n",
       "[5000 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as cPickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH = 30\n",
    "MAX_SENTS = 30\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_merge_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 30)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2896\n",
       "1    2104\n",
       "Name: quality_rank, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['quality_rank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5792"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2896/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/nobu_yamaguchi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "claims = []\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for idx in range(data_train.text.shape[0]):\n",
    "\n",
    "    text = clean_str(str(data_train.iloc[idx]['claims_text']))\n",
    "    texts.append(text)\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    claims.append(sentences)\n",
    "    labels.append(data_train.iloc[idx]['quality_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "data = np.zeros((len(texts), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 30, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentences in enumerate(claims):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k = 0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "            #for word in wordTokens:\n",
    "                if word in tokenizer.word_index.keys():\n",
    "                    if (k < MAX_SENT_LENGTH) and (tokenizer.word_index[word] < MAX_NB_WORDS):\n",
    "                        data[i, j, k] = tokenizer.word_index[word]\n",
    "                        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31722 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (5000, 30, 30)\n",
      "Shape of label tensor: (5000, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = np.arange(data.shape[0])\n",
    "#np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[indices]\n",
    "#labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive and negative reviews in traing and validation set\n",
      "[2320. 1680.]\n",
      "[576. 424.]\n"
     ]
    }
   ],
   "source": [
    "print('Number of positive and negative reviews in traing and validation set')\n",
    "print(y_train.sum(axis=0))\n",
    "print(y_val.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python helper libraries.\n",
    "import os, sys, re, json, time\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display\n",
    "\n",
    "# NumPy and SciPy for matrix ops\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "#from w266_common import utils, vocabulary, tf_embed_viz\n",
    "#import glove_helper; reload(glove_helper)\n",
    "\n",
    "#hands = glove_helper.Hands(ndim=100)  # 50, 100, 200, 300 dim are available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"data/glove/glove.6B.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data/glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"data/glove\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building Hierachical Attention network\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SENT_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttLayer(Layer):\n",
    "    def __init__(self, attention_dim):\n",
    "        self.init = initializers.get('normal')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)), name='W')\n",
    "        self.b = K.variable(self.init((self.attention_dim, )), name='b')\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)), name='u')\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "        super(AttLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # size of x :[batch_size, sel_len, attention_dim]\n",
    "        # size of u :[batch_size, attention_dim]\n",
    "        # uit = tanh(xW+b)\n",
    " \n",
    "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b)) #\n",
    "\n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "\n",
    "        ait = K.exp(ait)\n",
    "\n",
    "\n",
    "        #if mask is not None:\n",
    "        #    # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "        #    print('mask')\n",
    "        #    ait *= K.cast(mask, K.floatx())\n",
    "\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        ait = K.expand_dims(ait)\n",
    " \n",
    "        weighted_input = x * ait\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'att_layer_5/W:0' shape=(200, 100) dtype=float32> W\n",
      "tracking <tf.Variable 'att_layer_5/b:0' shape=(100,) dtype=float32> b\n",
      "tracking <tf.Variable 'att_layer_5/u:0' shape=(100, 1) dtype=float32> u\n"
     ]
    }
   ],
   "source": [
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sentence_input)\n",
    "l_lstm = Bidirectional(GRU(100, return_sequences=True))(embedded_sequences)\n",
    "l_att = AttLayer(100)(l_lstm)\n",
    "sentEncoder = Model(sentence_input, l_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "claims_encoder = TimeDistributed(sentEncoder)(claims_input)\n",
    "l_lstm_sent = Bidirectional(GRU(30, return_sequences=True))(claims_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 30, 60])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_lstm_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'att_layer_6/W:0' shape=(60, 100) dtype=float32> W\n",
      "tracking <tf.Variable 'att_layer_6/b:0' shape=(100,) dtype=float32> b\n",
      "tracking <tf.Variable 'att_layer_6/u:0' shape=(100, 1) dtype=float32> u\n"
     ]
    }
   ],
   "source": [
    "#l_att_sent = AttLayer(100)(l_lstm_sent)\n",
    "l_att_sent = AttLayer(100)(l_lstm_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_att_dense = Dense(100, activation='relu')(l_att_sent)\n",
    "l_att_dense = Dense(100, activation='relu')(l_att_dense)\n",
    "l_att_dense = Dense(100, activation='relu')(l_att_dense)\n",
    "l_att_sent_drop = Dropout(rate=0.2)(l_att_dense)\n",
    "preds = Dense(2, activation='sigmoid')(l_att_sent_drop)\n",
    "model = Model(claims_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.6817 - acc: 0.5739 - val_loss: 0.6860 - val_acc: 0.5640\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.6767 - acc: 0.5831 - val_loss: 0.6846 - val_acc: 0.5640\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.6757 - acc: 0.5825 - val_loss: 0.6838 - val_acc: 0.5650\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.6718 - acc: 0.5804 - val_loss: 0.6839 - val_acc: 0.5675\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.6601 - acc: 0.6060 - val_loss: 0.6884 - val_acc: 0.5385\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.6471 - acc: 0.6164 - val_loss: 0.6821 - val_acc: 0.5445\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.6333 - acc: 0.6395 - val_loss: 0.6862 - val_acc: 0.5665\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.6077 - acc: 0.6645 - val_loss: 0.7015 - val_acc: 0.5770\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.5750 - acc: 0.6970 - val_loss: 0.7307 - val_acc: 0.5595\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.5205 - acc: 0.7451 - val_loss: 0.7485 - val_acc: 0.5790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f775bb8d990>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network 0.3\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We changed max_sentence to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network - 0.3 Max sentence = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 32s 8ms/step - loss: 0.6586 - acc: 0.5811 - val_loss: 0.6518 - val_acc: 0.5730\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 27s 7ms/step - loss: 0.6520 - acc: 0.5786 - val_loss: 0.6519 - val_acc: 0.5845\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 27s 7ms/step - loss: 0.6512 - acc: 0.5895 - val_loss: 0.6475 - val_acc: 0.6060\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 28s 7ms/step - loss: 0.6464 - acc: 0.6056 - val_loss: 0.6496 - val_acc: 0.5830\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 28s 7ms/step - loss: 0.6381 - acc: 0.6302 - val_loss: 0.6447 - val_acc: 0.6110\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 28s 7ms/step - loss: 0.6363 - acc: 0.6341 - val_loss: 0.6381 - val_acc: 0.6320\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 27s 7ms/step - loss: 0.6231 - acc: 0.6515 - val_loss: 0.6368 - val_acc: 0.6300\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 27s 7ms/step - loss: 0.6104 - acc: 0.6668 - val_loss: 0.6373 - val_acc: 0.6450\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 27s 7ms/step - loss: 0.6034 - acc: 0.6745 - val_loss: 0.6307 - val_acc: 0.6305\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 28s 7ms/step - loss: 0.5729 - acc: 0.7032 - val_loss: 0.6265 - val_acc: 0.6445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f779de7ed50>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network - 0.3 Max sentence = 10\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network  .3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6465 - acc: 0.6551 - val_loss: 0.6522 - val_acc: 0.6390\n",
      "Epoch 2/5\n",
      "4000/4000 [==============================] - 10s 2ms/step - loss: 0.6405 - acc: 0.6610 - val_loss: 0.6508 - val_acc: 0.6390\n",
      "Epoch 3/5\n",
      "4000/4000 [==============================] - 10s 2ms/step - loss: 0.6377 - acc: 0.6611 - val_loss: 0.6483 - val_acc: 0.6390\n",
      "Epoch 4/5\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.6330 - acc: 0.6599 - val_loss: 0.6472 - val_acc: 0.6370\n",
      "Epoch 5/5\n",
      "4000/4000 [==============================] - 10s 2ms/step - loss: 0.6250 - acc: 0.6629 - val_loss: 0.6455 - val_acc: 0.6395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f87a01a0b10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network  max_sent = 15\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=5, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network  max_sent = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 49s 12ms/step - loss: 0.6416 - acc: 0.6392 - val_loss: 0.6457 - val_acc: 0.6230\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 45s 11ms/step - loss: 0.6301 - acc: 0.6575 - val_loss: 0.6401 - val_acc: 0.6430\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 45s 11ms/step - loss: 0.6262 - acc: 0.6637 - val_loss: 0.6351 - val_acc: 0.6305\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6213 - acc: 0.6596 - val_loss: 0.6302 - val_acc: 0.6435\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 45s 11ms/step - loss: 0.6132 - acc: 0.6680 - val_loss: 0.6246 - val_acc: 0.6515\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6025 - acc: 0.6718 - val_loss: 0.6187 - val_acc: 0.6500\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5952 - acc: 0.6870 - val_loss: 0.6259 - val_acc: 0.6655\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5831 - acc: 0.6949 - val_loss: 0.6253 - val_acc: 0.6665\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5670 - acc: 0.7091 - val_loss: 0.6558 - val_acc: 0.6415\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5514 - acc: 0.7181 - val_loss: 0.6252 - val_acc: 0.6540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fabc01b2c50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network  max_sent = 20\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network  max_sent = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 47s 12ms/step - loss: 0.6452 - acc: 0.6398 - val_loss: 0.6458 - val_acc: 0.6310\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6336 - acc: 0.6466 - val_loss: 0.6460 - val_acc: 0.6325\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6255 - acc: 0.6559 - val_loss: 0.6405 - val_acc: 0.6370\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6160 - acc: 0.6724 - val_loss: 0.6265 - val_acc: 0.6485\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6135 - acc: 0.6699 - val_loss: 0.6205 - val_acc: 0.6520\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6017 - acc: 0.6805 - val_loss: 0.6250 - val_acc: 0.6620\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5933 - acc: 0.6852 - val_loss: 0.6200 - val_acc: 0.6645\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5773 - acc: 0.7081 - val_loss: 0.6333 - val_acc: 0.6530\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5533 - acc: 0.7225 - val_loss: 0.6283 - val_acc: 0.6655\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5204 - acc: 0.7396 - val_loss: 0.6427 - val_acc: 0.6465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fab8d551e10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network  max_sent = 20\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network  max_sent = 20 dropout rate = 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 47s 12ms/step - loss: 0.6423 - acc: 0.6388 - val_loss: 0.6389 - val_acc: 0.6350\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6275 - acc: 0.6580 - val_loss: 0.6410 - val_acc: 0.6370\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6241 - acc: 0.6683 - val_loss: 0.6448 - val_acc: 0.6365\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6183 - acc: 0.6619 - val_loss: 0.6339 - val_acc: 0.6385\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6072 - acc: 0.6790 - val_loss: 0.6231 - val_acc: 0.6435\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6062 - acc: 0.6770 - val_loss: 0.6352 - val_acc: 0.6340\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5931 - acc: 0.6908 - val_loss: 0.6217 - val_acc: 0.6360\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5809 - acc: 0.7050 - val_loss: 0.6369 - val_acc: 0.6365\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5545 - acc: 0.7224 - val_loss: 0.6431 - val_acc: 0.6560\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5248 - acc: 0.7479 - val_loss: 0.6696 - val_acc: 0.6180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fabcafe3d90>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network  max_sent = 20 dropout rate = 0.4\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network  max_sent = 20 dropout rate = 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 47s 12ms/step - loss: 0.6426 - acc: 0.6288 - val_loss: 0.6511 - val_acc: 0.6280\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6323 - acc: 0.6505 - val_loss: 0.6398 - val_acc: 0.6355\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6276 - acc: 0.6560 - val_loss: 0.6403 - val_acc: 0.6345\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6139 - acc: 0.6689 - val_loss: 0.6317 - val_acc: 0.6365\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 45s 11ms/step - loss: 0.6105 - acc: 0.6705 - val_loss: 0.6252 - val_acc: 0.6480\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 46s 11ms/step - loss: 0.6059 - acc: 0.6780 - val_loss: 0.6317 - val_acc: 0.6510\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5913 - acc: 0.6915 - val_loss: 0.6298 - val_acc: 0.6495\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5783 - acc: 0.6977 - val_loss: 0.6203 - val_acc: 0.6460\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5592 - acc: 0.7194 - val_loss: 0.6725 - val_acc: 0.6540\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.5324 - acc: 0.7365 - val_loss: 0.6520 - val_acc: 0.6275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fab8cd27d10>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network  max_sent = 20 dropout rate = 0.2\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network  max_sent = 20 dropout rate = 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "4000/4000 [==============================] - 55s 14ms/step - loss: 0.6427 - acc: 0.6334 - val_loss: 0.6411 - val_acc: 0.6300\n",
      "Epoch 2/8\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.6301 - acc: 0.6550 - val_loss: 0.6438 - val_acc: 0.6285\n",
      "Epoch 3/8\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.6315 - acc: 0.6491 - val_loss: 0.6354 - val_acc: 0.6305\n",
      "Epoch 4/8\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.6260 - acc: 0.6566 - val_loss: 0.6326 - val_acc: 0.6370\n",
      "Epoch 5/8\n",
      "4000/4000 [==============================] - 51s 13ms/step - loss: 0.6156 - acc: 0.6672 - val_loss: 0.6406 - val_acc: 0.6190\n",
      "Epoch 6/8\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.6148 - acc: 0.6706 - val_loss: 0.6355 - val_acc: 0.6490\n",
      "Epoch 7/8\n",
      "4000/4000 [==============================] - 51s 13ms/step - loss: 0.6017 - acc: 0.6854 - val_loss: 0.6282 - val_acc: 0.6550\n",
      "Epoch 8/8\n",
      "4000/4000 [==============================] - 53s 13ms/step - loss: 0.5857 - acc: 0.6913 - val_loss: 0.6330 - val_acc: 0.6550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fab6e4318d0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network  max_sent = 20 dropout rate = 0.3\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=8, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network  max_sent = 25 dropout rate = 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nobu_yamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "4000/4000 [==============================] - 62s 15ms/step - loss: 0.6309 - acc: 0.6459 - val_loss: 0.6446 - val_acc: 0.6310\n",
      "Epoch 2/8\n",
      "4000/4000 [==============================] - 56s 14ms/step - loss: 0.6199 - acc: 0.6582 - val_loss: 0.6291 - val_acc: 0.6495\n",
      "Epoch 3/8\n",
      "4000/4000 [==============================] - 56s 14ms/step - loss: 0.6158 - acc: 0.6606 - val_loss: 0.6274 - val_acc: 0.6445\n",
      "Epoch 4/8\n",
      "4000/4000 [==============================] - 56s 14ms/step - loss: 0.6133 - acc: 0.6675 - val_loss: 0.6323 - val_acc: 0.6565\n",
      "Epoch 5/8\n",
      "4000/4000 [==============================] - 57s 14ms/step - loss: 0.6049 - acc: 0.6740 - val_loss: 0.6291 - val_acc: 0.6665\n",
      "Epoch 6/8\n",
      "4000/4000 [==============================] - 56s 14ms/step - loss: 0.5983 - acc: 0.6762 - val_loss: 0.6131 - val_acc: 0.6705\n",
      "Epoch 7/8\n",
      "4000/4000 [==============================] - 56s 14ms/step - loss: 0.5869 - acc: 0.6842 - val_loss: 0.6066 - val_acc: 0.6725\n",
      "Epoch 8/8\n",
      "4000/4000 [==============================] - 56s 14ms/step - loss: 0.5724 - acc: 0.7017 - val_loss: 0.6230 - val_acc: 0.6730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc826f71c10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network  max_sent = 25 dropout rate = 0.3\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=8, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network  max_sent = 30 dropout rate = 0.4 epoch = 8\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "4000/4000 [==============================] - 71s 18ms/step - loss: 0.6321 - acc: 0.6434 - val_loss: 0.6329 - val_acc: 0.6435\n",
      "Epoch 2/8\n",
      "4000/4000 [==============================] - 65s 16ms/step - loss: 0.6222 - acc: 0.6604 - val_loss: 0.6396 - val_acc: 0.6300\n",
      "Epoch 3/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.6165 - acc: 0.6543 - val_loss: 0.6301 - val_acc: 0.6470\n",
      "Epoch 4/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.6116 - acc: 0.6724 - val_loss: 0.6221 - val_acc: 0.6525\n",
      "Epoch 5/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.6068 - acc: 0.6791 - val_loss: 0.6193 - val_acc: 0.6615\n",
      "Epoch 6/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.5988 - acc: 0.6804 - val_loss: 0.6098 - val_acc: 0.6705\n",
      "Epoch 7/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.5823 - acc: 0.6888 - val_loss: 0.6131 - val_acc: 0.6610\n",
      "Epoch 8/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.5702 - acc: 0.6990 - val_loss: 0.6189 - val_acc: 0.6730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa47ecafa10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network  max_sent = 30 dropout rate = 0.4 epoch = 8\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=8, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network  max_sent = 30 dropout rate = 0.2 epoch = 8\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.6259 - acc: 0.6516 - val_loss: 0.6309 - val_acc: 0.6460\n",
      "Epoch 2/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.6148 - acc: 0.6571 - val_loss: 0.6283 - val_acc: 0.6470\n",
      "Epoch 3/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.6121 - acc: 0.6662 - val_loss: 0.6238 - val_acc: 0.6630\n",
      "Epoch 4/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.6076 - acc: 0.6660 - val_loss: 0.6195 - val_acc: 0.6590\n",
      "Epoch 5/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.5995 - acc: 0.6800 - val_loss: 0.6170 - val_acc: 0.6715\n",
      "Epoch 6/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.5910 - acc: 0.6867 - val_loss: 0.6312 - val_acc: 0.6675\n",
      "Epoch 7/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.5819 - acc: 0.6946 - val_loss: 0.6091 - val_acc: 0.6685\n",
      "Epoch 8/8\n",
      "4000/4000 [==============================] - 64s 16ms/step - loss: 0.5713 - acc: 0.7088 - val_loss: 0.6139 - val_acc: 0.6845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa462ad4a10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - Hierachical attention network  max_sent = 30 dropout rate = 0.2 epoch = 8\")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=8, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
